<!DOCTYPE html><html lang="zh-CN"><head><meta charset="UTF-8"><meta name="viewport" content="width=device-width"><meta name="theme-color" content="#222"><meta name="generator" content="Hexo 6.3.0"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png"><link rel="mask-icon" href="/images/logo.svg" color="#222"><link rel="stylesheet" href="/css/main.css"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.5.2/css/all.min.css" integrity="sha256-XOqroi11tY4EFQMR9ZYwZWKj5ZXiftSx36RRuC3anlA=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/animate.css/3.1.1/animate.min.css" integrity="sha256-PR7ttpcvz8qrF57fur/yAx1qXMFJeJFiA6pSzWi0OIE=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.css" integrity="sha256-gkQVf8UKZgQ0HyuxL/VnacadJ+D2Kox2TCEBuNQg5+w=" crossorigin="anonymous"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/themes/blue/pace-theme-fill-left.css"><script src="https://cdnjs.cloudflare.com/ajax/libs/pace/1.2.4/pace.min.js" integrity="sha256-gqd7YTjg/BtfqWSwsJOvndl0Bxc8gFImLEkXQT8+qj0=" crossorigin="anonymous"></script><script class="next-config" data-name="main" type="application/json">{"hostname":"www.victorchu.info","root":"/","images":"/images","scheme":"Muse","darkmode":false,"version":"8.20.0","exturl":false,"sidebar":{"position":"left","width_expanded":320,"width_dual_column":240,"display":"post","padding":18,"offset":12,"onmobile":true},"copycode":{"enable":true,"style":"flat"},"fold":{"enable":true,"height":500},"bookmark":{"enable":true,"color":"#222","save":"auto"},"mediumzoom":false,"lazyload":true,"pangu":true,"comments":{"style":"tabs","active":"waline","storage":false,"lazyload":false,"nav":null,"activeClass":"waline"},"stickytabs":false,"motion":{"enable":true,"async":false,"transition":{"menu_item":"fadeInDown","post_block":"fadeIn","post_header":"fadeInDown","post_body":"fadeInDown","coll_header":"fadeInLeft","sidebar":"fadeInUp"}},"prism":false,"i18n":{"placeholder":"搜索...","empty":"没有找到任何搜索结果：${query}","hits_time":"找到 ${hits} 个搜索结果（用时 ${time} 毫秒）","hits":"找到 ${hits} 个搜索结果"},"algolia":{"appID":"X9UOD4FSUP","apiKey":"fa32db1f02073025c69da8ebad0a6aa6","indexName":"hexo-next-blog","hits":{"per_page":10}}}</script><script src="/js/config.js"></script><meta name="description" content="blog about programming."><meta property="og:type" content="website"><meta property="og:title" content="代码之旅"><meta property="og:url" content="https://www.victorchu.info/page/9/index.html"><meta property="og:site_name" content="代码之旅"><meta property="og:description" content="blog about programming."><meta property="og:locale" content="zh_CN"><meta property="article:author" content="Victor Chu"><meta name="twitter:card" content="summary"><link rel="canonical" href="https://www.victorchu.info/page/9/"><script class="next-config" data-name="page" type="application/json">{"sidebar":"","isHome":true,"isPost":false,"lang":"zh-CN","comments":"","permalink":"","path":"page/9/index.html","title":""}</script><script class="next-config" data-name="calendar" type="application/json">""</script><title>代码之旅</title><script src="/js/third-party/analytics/baidu-analytics.js"></script><script async src="https://hm.baidu.com/hm.js?277fc29fa80de77c97f4f62b69e94233"></script><link rel="dns-prefetch" href="walineui.victorchu.info"><link rel="stylesheet" type="text/css" href="/css/injector/main.css"><link rel="preload" as="style" href="/css/injector/light.css"><link rel="preload" as="style" href="/css/injector/dark.css"><noscript><link rel="stylesheet" href="/css/noscript.css"></noscript><style>.darkmode--activated{--body-bg-color:#282828;--content-bg-color:#333;--card-bg-color:#555;--text-color:#ccc;--blockquote-color:#bbb;--link-color:#ccc;--link-hover-color:#eee;--brand-color:#ddd;--brand-hover-color:#ddd;--table-row-odd-bg-color:#282828;--table-row-hover-bg-color:#363636;--menu-item-bg-color:#555;--btn-default-bg:#222;--btn-default-color:#ccc;--btn-default-border-color:#555;--btn-default-hover-bg:#666;--btn-default-hover-color:#ccc;--btn-default-hover-border-color:#666;--highlight-background:#282b2e;--highlight-foreground:#a9b7c6;--highlight-gutter-background:#34393d;--highlight-gutter-foreground:#9ca9b6}.darkmode--activated img{opacity:.75}.darkmode--activated img:hover{opacity:.9}.darkmode--activated code{color:#69dbdc;background:0 0}button.darkmode-toggle{z-index:9999}.darkmode-ignore,img{display:flex!important}.beian img{display:inline-block!important}</style><link rel="alternate" href="/atom.xml" title="代码之旅" type="application/atom+xml"></head><body itemscope itemtype="http://schema.org/WebPage" class="use-motion"><div class="headband"></div><main class="main"><div class="column"><header class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="site-brand-container"><div class="site-nav-toggle"><div class="toggle" aria-label="切换导航栏" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div></div><div class="site-meta"><a href="/" class="brand" rel="start"><i class="logo-line"></i><h1 class="site-title">代码之旅</h1><i class="logo-line"></i></a><p class="site-subtitle" itemprop="description">I love Coding !</p></div><div class="site-nav-right"><div class="toggle popup-trigger" aria-label="搜索" role="button"><i class="fa fa-search fa-fw fa-lg"></i></div></div></div><nav class="site-nav"><ul class="main-menu menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="fa fa-home fa-fw"></i>首页</a></li><li class="menu-item menu-item-about"><a href="/about/" rel="section"><i class="fa fa-user fa-fw"></i>关于</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="fa fa-tags fa-fw"></i>标签<span class="badge">120</span></a></li><li class="menu-item menu-item-categories"><a href="/categories/" rel="section"><i class="fa fa-th fa-fw"></i>分类<span class="badge">90</span></a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="fa fa-archive fa-fw"></i>归档<span class="badge">227</span></a></li><li class="menu-item menu-item-search"><a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索</a></li></ul></nav><div class="search-pop-overlay"><div class="popup search-popup"><div class="search-header"><span class="search-icon"><i class="fa fa-search"></i></span><div class="search-input-container"></div><span class="popup-btn-close" role="button"><i class="fa fa-times-circle"></i></span></div><div class="search-result-container"><div class="algolia-stats"><hr></div><div class="algolia-hits"></div><div class="algolia-pagination"></div></div></div></div></header><aside class="sidebar"><div class="sidebar-inner sidebar-overview-active"><ul class="sidebar-nav"><li class="sidebar-nav-toc">文章目录</li><li class="sidebar-nav-overview">站点概览</li></ul><div class="sidebar-panel-container"><div class="post-toc-wrap sidebar-panel"></div><div class="site-overview-wrap sidebar-panel"><div class="site-author animated" itemprop="author" itemscope itemtype="http://schema.org/Person"><img class="site-author-image" itemprop="image" alt="Victor Chu" src="/images/victor-blog-head.webp"><p class="site-author-name" itemprop="name">Victor Chu</p><div class="site-description" itemprop="description">blog about programming.</div></div><div class="site-state-wrap animated"><nav class="site-state"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">227</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-categories"><a href="/categories/"><span class="site-state-item-count">90</span> <span class="site-state-item-name">分类</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/"><span class="site-state-item-count">120</span> <span class="site-state-item-name">标签</span></a></div></nav></div><div class="links-of-author animated"><span class="links-of-author-item"><a href="https://github.com/chutian0610" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;chutian0610" rel="noopener me" target="_blank"><i class="fab fa-github fa-fw"></i>GitHub</a> </span><span class="links-of-author-item"><a href="mailto:victorchu0610@outlook.com" title="E-Mail → mailto:victorchu0610@outlook.com" rel="noopener me" target="_blank"><i class="fa fa-envelope fa-fw"></i>E-Mail</a> </span><span class="links-of-author-item"><a href="https://www.zhihu.com/people/victorchu" title="Zhihu → https:&#x2F;&#x2F;www.zhihu.com&#x2F;people&#x2F;victorchu" rel="noopener me" target="_blank"><i class="fab fa-zhihu fa-fw"></i>Zhihu</a> </span><span class="links-of-author-item"><a href="/images/Wechat.webp" title="WeChat → &#x2F;images&#x2F;Wechat.webp" rel="noopener me"><i class="fa-brands fa-weixin fa-fw"></i>WeChat</a></span></div></div></div></div><div class="sidebar-inner sidebar-blogroll"><div class="links-of-blogroll animated"><div class="links-of-blogroll-title"><i class="fa fa-globe fa-fw"></i> 链接</div><ul class="links-of-blogroll-list"><li class="links-of-blogroll-item"><a href="https://www.tpfuture.top/" title="https:&#x2F;&#x2F;www.tpfuture.top&#x2F;" rel="noopener" target="_blank">一水轩</a></li></ul></div></div></aside></div><div class="main-inner index posts-expand"><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/8bd607ed/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/8bd607ed/" class="post-title-link" itemprop="url">What Every Programmer Should Know About Memory (3)</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-11-08 11:03:34" itemprop="dateCreated datePublished" datetime="2020-11-08T11:03:34+08:00">2020-11-08</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-11-11 14:59:32" itemprop="dateModified" datetime="2024-11-11T14:59:32+08:00">2024-11-11</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Computer/" itemprop="url" rel="index"><span itemprop="name">Computer</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/8bd607ed/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/8bd607ed/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/8bd607ed/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>35k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>58 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本文翻译自 <a target="_blank" rel="noopener" href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf#link=pdf">What Every Programmer Should Know About Memory</a>的第6章</p></blockquote><h1 id="程序开发者能做些什么？">程序开发者能做些什么？</h1><p>在前面几节的描述之后，无疑地，程序开发者有非常非常多 – 正向或者负向地 –– 影响程序效能的机会。而这里仅讨论与memory有关的操作。我们将会全面地解释这些部分，由最底层的物理 RAM 存取以及 L1 cache开始，一路涵盖到影响memory管理的操作系统功能。</p><h2 id="绕过cache">绕过cache</h2><p>当数据被产生并且没有（立即）再次使用时，内存存储操作首先读取完整的缓存行，然后修改缓存的数据，这点对性能不利。此操作将可能会再次需要的数据从缓存中淘汰，将缓存让给那些短期内不会再次被用到的数据。对于大型数据结构尤其如此，如矩阵，它们被填充，然后再使用。在矩阵的最后一个元素被填充之前，第一个元素就会因为矩阵太大被踢出cache，导致写入cache无效。</p><p>对于这类情况，处理器提供对**非暂存(non-temporal)**写入操作的支援。在这种情况下，非暂存指的是数据不会很快被重用，所以没有任何缓存它的理由。这些非暂存的写入操作不会先读取cache行然后才修改它；相反，新内容直接写入内存。</p><p>这听起来可能很昂贵，但并不一定如此。处理器会试著使用写合并（见 3.3.3 节）来填入整个cache行。若是成功，那么memory读取操作是完全不必要的。如 x86 以及 x86-64 架构，gcc 提供若干intrinsic(编译器内部函数):</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;emmintrin.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> _mm_stream_si32(<span class="type">int</span> *p, <span class="type">int</span> a);</span><br><span class="line"><span class="type">void</span> _mm_stream_si128(<span class="type">int</span> *p, __m128i a);</span><br><span class="line"><span class="type">void</span> _mm_stream_pd(<span class="type">double</span> *p, __m128d a);</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;xmmintrin.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> _mm_stream_pi(__m64 *p, __m64 a);</span><br><span class="line"><span class="type">void</span> _mm_stream_ps(<span class="type">float</span> *p, __m128 a);</span><br><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;ammintrin.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> _mm_stream_sd(<span class="type">double</span> *p, __m128d a);</span><br><span class="line"><span class="type">void</span> _mm_stream_ss(<span class="type">float</span> *p, __m128 a);</span><br></pre></td></tr></table></figure><p>最有效率地使用这些指令的情况是一次处理大量数据。数据从内存加载，在一个或多个步骤中处理，然后写回内存。数据“流”过处理器，因此有内在函数的名称。</p><p>内存地址必须各自对齐至 8 或 16 byte。在使用多媒体扩充（multimedia extension）的程序码中，也可以用这些非暂存的版本替换通常的 <code>_mm_store_*</code> 指令。我们并没有在 A.1 节的矩阵相乘程序中这么做，因为写入的值会在短时间内被再次使用。这是一个使用流指令没有用的例子。6.2.1 节会更加深入这段程序码。</p><p>处理器的写合并缓冲区可以将部分写入cache行的请求延迟一小段时间。一个接着一个执行所有修改单一cache行的指令，以令合并写入能真的发挥功用通常是必要的。以下是一个如何实践的例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;emmintrin.h&gt;</span></span></span><br><span class="line"><span class="type">void</span> <span class="title function_">setbytes</span><span class="params">(<span class="type">char</span> *p, <span class="type">int</span> c)</span></span><br><span class="line">&#123;</span><br><span class="line">  __m128i i = _mm_set_epi8(c, c, c, c,</span><br><span class="line">                           c, c, c, c,</span><br><span class="line">                           c, c, c, c,</span><br><span class="line">                           c, c, c, c);</span><br><span class="line">  _mm_stream_si128((__m128i *)&amp;p[<span class="number">0</span>], i);</span><br><span class="line">  _mm_stream_si128((__m128i *)&amp;p[<span class="number">16</span>], i);</span><br><span class="line">  _mm_stream_si128((__m128i *)&amp;p[<span class="number">32</span>], i);</span><br><span class="line">  _mm_stream_si128((__m128i *)&amp;p[<span class="number">48</span>], i);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>假设指针 <code>p</code> 被适当地对齐，调用这个函数会将指向的cache行中的所有byte设为 <code>c</code>。合并写入逻辑会看到四个生成的 <code>movntdq</code> 指令，并仅在最后一个指令被执行之后，才对memory发出写入命令。总而言之，这段程序不仅避免在写入前读取cache行，也避免cache被并非立即需要的数据污染。这在某些情况下会有巨大的好处。一个经常使用这项技术的例子是C函数库中的<code>memset</code>函数，它在处理大块memory时使用如上所述的代码。</p><p>一些架构提供了专门的解决方案。PowerPC架构定义了可用于清除整个缓存行的<code>dcbz</code>指令。这个指令不会真的绕过cache，因为cache行仍会被分配来存放结果，但没有任何数据会从memory被读出来。它比非暂存存储指令更受限制，因为缓存行只能设置为全零，并且它会调整缓存（如果数据是非时态的），但不需要写合并来实现。</p><p>为了查看非暂存指令的运行情况，我们将查看一个新的测试，该测试用于测量对矩阵的写入性能(矩阵被组织为一个二维数组)。编译器在内存中布置矩阵，以便最左边（第一个）索引寻址内存中元素按顺序排列的行。右边（第二个）索引行中的元素。测试程序以两种方式迭代矩阵：</p><ol><li>增加内部循环中的列索引</li><li>增加内部循环中的行索引。</li></ol><p>其行为如图 6.1 所示。</p><figure><img data-src="/posts/8bd607ed/figure-6.1.webp" alt="图 6.1：矩阵存取模式"><figcaption>图 6.1：矩阵存取模式</figcaption></figure><p>我们测量初始化<code>3000×3000</code> 矩阵所需的时间。为了了解内存的行为，我们使用不使用缓存的存储指令。在IA-32处理器上，“non-temporal hint”用于此目的。为了进行对比，我们还测量普通的存储操作。结果见表6.1。</p><figure><table><tr><th rowspan="2"></th><th colspan="2">内部顺序循环</th></tr><tr><th>行</th><th>列</th></tr><tr><td>一般</td><td>0.048s</td><td>0.127s</td></tr><tr><td>非暂存</td><td>0.048s</td><td>0.160s</td></tr></table><figcaption>表 6.1：矩阵初始化计时</figcaption></figure><p>对于使用缓存的正常写入，我们看到了预期的结果：如果顺序使用内存，我们会得到更好的结果，整个操作耗时0.048秒转换下大约750MB/s，相比之下，或多或少的随机访问需要0.127秒（大约280MB/s）。矩阵已经大到缓存基本上失效。</p><p>这里我们主要感兴趣的部分是绕过缓存的写入。令人惊讶的是，这里的顺序访问和使用缓存的情况下一样快。造成这种结果的原因是进程或正在执行写合并，如上所述。此外，非暂存写入的内存排序规则被放宽了: 程序需要显式插入内存屏障（x86和x86-64处理器的<code>sfence</code>指令）。这意味着处理器在写回数据时有更多的自由，从而尽可能地使用可用带宽。</p><p>在内部循环中按列访问的情况下，情况就不同了。未缓存访问的结果比缓存访问的结果慢得多（0.16秒，约225MB/s）。在这里，我们可以看到不可能进行写合并，每个存储单元必须单独寻址。这需要不断地在RAM芯片中在所有相关延迟下选择新行。结果比缓存运行的结果差25%。</p><p>在读取方面，直到最近，处理器除了使用非暂存访问（NTA）预取指令的弱提示之外，还缺乏相应的支持。没有与<code>写入合并</code>对等的读取操作，这对于不可被缓存的内存，如内存映射(memory-mapped)I/O，来说尤其糟糕。Intel 附带 SSE4.1 扩充引入 NTA 载入。它们以一些流载入缓冲区（streaming load buffer）实现；每个缓冲区都包含一条cache line。给定cache line的第一个 <code>movntdqa</code> 指令会将cache line载入一个缓冲区，可能会替换另一条cache line。随后，对同一个cache line、以 16 byte对齐的存取操作将会由载入缓冲区以少量的成本来提供服务。除非有其他原因，否则cache line不会被加载到缓存中，从而可以在不污染缓存的情况下加载大量内存。编译器为此指令提供了一个intrinsic函数：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;smmintrin.h&gt;</span></span></span><br><span class="line">__m128i _mm_stream_load_si128 (__m128i *p);</span><br></pre></td></tr></table></figure><p>这个intrinsic函数应该要以16字节块的地址作为参数多次执行，直到每个缓存行都被读取。在这时才应该开始处理下一个缓存行。由于有几个流读缓冲区，因此可以同时从两个内存位置读取。</p><p>我们应该从这个实验中得到的是，现代CPU非常好地优化了非缓存写入，最近甚至可以优化读取访问，只要它们是顺序操作。当处理只使用一次的大型数据结构时，这些知识会非常有用。其次，缓存可以帮助降低随机内存访问的部分（但不是全部）成本。由于RAM访问的实现，本例中的随机访问速度降低了70%。在实现改变之前，应该尽可能避免随机访问。</p><p>在关于预取的章节中，我们将再次查看非暂存标志。</p><h2 id="cache-访问">cache 访问</h2><p>希望提高程序性能的程序员会发现最好关注影响一级缓存的变化，因为这些变化可能会产生最好的结果。在将讨论扩展到其他级别之前，我们将首先讨论它。显然，一级缓存的所有优化也会影响其他缓存。所有内存访问的主题都是一样的：提高局部性（空间和时间），对齐代码和数据。</p><h3 id="优化一级数据缓存访问">优化一级数据缓存访问</h3><p>在 3.3 节，我们已经看过 L1d cache的有效使用能够提升效能。在本节中，我们将展示什么样的代码更改有助于提高性能。延续上一节，我们首先聚焦在顺序访问内存的优化。如第3.3节的数字所示，当顺序访问内存时，处理器会自动预取数据。</p><p>使用的示例代码是矩阵相乘。我们使用两个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1000</mn><mo>×</mo><mn>1000</mn></mrow><annotation encoding="application/x-tex">1000\times1000</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">1000</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">×</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">1000</span></span></span></span> 双元素的平方矩阵。对于那些忘记数学的人，给定元素为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">a_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7167em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">b_{ij}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.9805em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span></span></span></span> 的矩阵 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal">A</span></span></span></span> 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.05017em">B</span></span></span></span> ，<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>0</mn><mo>≤</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>&lt;</mo><mi>N</mi></mrow><annotation encoding="application/x-tex">0 \leq i,j &lt; N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7804em;vertical-align:-.136em"></span><span class="mord">0</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">≤</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.854em;vertical-align:-.1944em"></span><span class="mord mathnormal">i</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord mathnormal" style="margin-right:.05724em">j</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">&lt;</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span>，乘积为:</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mi>B</mi><msub><mo stretchy="false">)</mo><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>a</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>b</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>a</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><msub><mi>b</mi><mrow><mn>1</mn><mi>j</mi></mrow></msub><mo>+</mo><msub><mi>a</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><msub><mi>b</mi><mrow><mn>2</mn><mi>j</mi></mrow></msub><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>a</mi><mrow><mi>i</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><msub><mi>b</mi><mrow><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">(AB)_{ij} = \sum^{N - 1}_{k = 0} a_{ik} b_{kj} = a_{i1} b_{1j} + a_{i2} b_{2j} + \cdots + a_{i(N - 1)} b_{(N - 1)j}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-.2861em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8479em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">kj</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.9805em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">1</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.9805em;vertical-align:-.2861em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">2</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6667em;vertical-align:-.0833em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.0496em;vertical-align:-.3552em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3552em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3552em"><span></span></span></span></span></span></span></span></span></span></span></p><p>一个直观的 C 实现看起来可能像这样:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">  <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; ++j)</span><br><span class="line">    <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; N; ++k)</span><br><span class="line">      res[i][j] += mul1[i][k] * mul2[k][j];</span><br></pre></td></tr></table></figure><p>两个输入矩阵为 <code>mul1</code> 与 <code>mul2</code>。假定结果矩阵 <code>res</code> 全被初始化为零。这是一个很好的简单实现。但是很明显，我们会遇到图6.1中解释的问题。当<code>mul1</code>被顺序访问时，inner循环将增加<code>mul2</code>的行数。这意味着<code>mul1</code>像图6.1中的左矩阵一样处理，而<code>mul2</code>像右矩阵一样处理。这可能不太好。</p><p>有一种可能的补救方法可以很容易地尝试。由于矩阵中的每个元素都被多次访问，在使用第二个矩阵mul2之前，重新排列（“转置”，用数学术语来说）可能是值得的。</p><p><span class="katex-display"><span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mo stretchy="false">(</mo><mi>A</mi><mi>B</mi><msub><mo stretchy="false">)</mo><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><munderover><mo>∑</mo><mrow><mi>k</mi><mo>=</mo><mn>0</mn></mrow><mrow><mi>N</mi><mo>−</mo><mn>1</mn></mrow></munderover><msub><mi>a</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msubsup><mi>b</mi><mrow><mi>j</mi><mi>k</mi></mrow><mtext>T</mtext></msubsup><mo>=</mo><msub><mi>a</mi><mrow><mi>i</mi><mn>1</mn></mrow></msub><msubsup><mi>b</mi><mrow><mi>j</mi><mn>1</mn></mrow><mtext>T</mtext></msubsup><mo>+</mo><msub><mi>a</mi><mrow><mi>i</mi><mn>2</mn></mrow></msub><msubsup><mi>b</mi><mrow><mi>j</mi><mn>2</mn></mrow><mtext>T</mtext></msubsup><mo>+</mo><mo>⋯</mo><mo>+</mo><msub><mi>a</mi><mrow><mi>i</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow></msub><msubsup><mi>b</mi><mrow><mi>j</mi><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><mtext>T</mtext></msubsup></mrow><annotation encoding="application/x-tex">(AB)_{ij} = \sum^{N - 1}_{k = 0} a_{ik} b^{\text{T}}_{jk} = a_{i1} b^{\text{T}}_{j1} + a_{i2} b^{\text{T}}_{j2} + \cdots + a_{i(N - 1)} b^{\text{T}}_{j(N - 1)}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1.0361em;vertical-align:-.2861em"></span><span class="mopen">(</span><span class="mord mathnormal">A</span><span class="mord mathnormal" style="margin-right:.05017em">B</span><span class="mclose"><span class="mclose">)</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">ij</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.2861em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:3.1304em;vertical-align:-1.3021em"></span><span class="mop op-limits"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:1.8283em"><span style="top:-1.8479em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">k</span><span class="mrel mtight">=</span><span class="mord mtight">0</span></span></span></span><span style="top:-3.05em"><span class="pstrut" style="height:3.05em"></span><span><span class="mop op-symbol large-op">∑</span></span></span><span style="top:-4.3em;margin-left:0"><span class="pstrut" style="height:3.05em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:1.3021em"><span></span></span></span></span></span><span class="mspace" style="margin-right:.1667em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3361em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">ik</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913em"><span style="top:-2.453em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.03148em">jk</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">T</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3831em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:1.2744em;vertical-align:-.3831em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">1</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913em"><span style="top:-2.453em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mord mtight">1</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">T</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3831em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.2744em;vertical-align:-.3831em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3117em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mord mtight">2</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913em"><span style="top:-2.453em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mord mtight">2</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">T</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3831em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:.6667em;vertical-align:-.0833em"></span><span class="minner">⋯</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">+</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1.3383em;vertical-align:-.447em"></span><span class="mord"><span class="mord mathnormal">a</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3448em"><span style="top:-2.5198em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">i</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.3552em"><span></span></span></span></span></span></span><span class="mord"><span class="mord mathnormal">b</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.8913em"><span style="top:-2.428em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.05724em">j</span><span class="mopen mtight">(</span><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span><span class="mbin mtight">−</span><span class="mord mtight">1</span><span class="mclose mtight">)</span></span></span></span><span style="top:-3.113em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord text mtight"><span class="mord mtight">T</span></span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.447em"><span></span></span></span></span></span></span></span></span></span></span></p><p>在转置之后（通常以上标「T」表示），我们现在顺序地迭代两个矩阵。就 C 程序而言，现在看起来像这样：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">double</span> tmp[N][N];</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">  <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; ++j)</span><br><span class="line">    tmp[i][j] = mul2[j][i];</span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; ++i)</span><br><span class="line">  <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; ++j)</span><br><span class="line">    <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; N; ++k)</span><br><span class="line">      res[i][j] += mul1[i][k] * tmp[j][k];</span><br></pre></td></tr></table></figure><p>我们创建一个临时变量来存储转置矩阵。这需要使用额外的内存，但这一成本有望收回，因为每列1000次非顺序访问更昂贵（至少在现代硬件上）。一些性能测试的时间。在主频为2666MHz的英特尔酷睿2上的结果是（以时钟周期为单位）</p><table><tr><th></th><th>原始</th><th>转置</th></tr><tr><th>周期数</th><td>16,765,297,870</td><td>3,922,373,010</td></tr><tr><th>相对值</th><td>100%</td><td>23.4%</td></tr></table><p>虽然只是个简单的矩阵转置，但我们能达到 76.6% 的加速！复制操作的损失完全被弥补。1000 次非循序存取真的很伤。</p><p>下个问题是，我们是否能做得更好。无论如何，我们确实需要一个不需额外复制的替代方法。我们并不是总有资源能进行复制：矩阵可能太大、或者可用的memory太小。</p><p>寻找替代实现应该从仔细检查所涉及的数学和原始实现执行的操作开始。三角数学知识使我们能够看到，只要每个加数（addend）恰好出现一次，结果矩阵的每个元素的加法执行顺序就无关紧要<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。这个理解让我们能够寻找将执行在原始程序码内部循环的加法重新排列的解法。</p><p>现在，让我们来检验在原始程序码执行中的实际问题。被存取的 <code>mul2</code> 元素的顺序为：<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0, 0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">0</span><span class="mclose">)</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1, 0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">0</span><span class="mclose">)</span></span></span></span>、 … 、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mi>N</mi><mo>−</mo><mn>1</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(N - 1, 0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord mathnormal" style="margin-right:.10903em">N</span><span class="mspace" style="margin-right:.2222em"></span><span class="mbin">−</span><span class="mspace" style="margin-right:.2222em"></span></span><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">0</span><span class="mclose">)</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0,1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>、<span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>1</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(1, 1)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">1</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">1</span><span class="mclose">)</span></span></span></span>…。元素 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><mn>0</mn><mo separator="true">,</mo><mn>0</mn><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(0, 0)</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:1em;vertical-align:-.25em"></span><span class="mopen">(</span><span class="mord">0</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">0</span><span class="mclose">)</span></span></span></span> 与 $ (0, 1)$ 位于同一个cache行中，但在内部循环完成一轮的时候，这个cache行早已被逐出。以这个例子而言，每一轮内部循环都需要 –– 对三个矩阵的每一个而言 –– 1000 个cache行（Core 2 处理器为 64 byte）。这加起来远比 L1d 可用的 32k 还多。</p><p>但若是我们在执行内部循环的期间，一起处理中间循环的两次迭代呢？在这个情况下，我们使用两个来自必定在 L1d 中的cache行的 <code>double</code> 值。我们将 L1d 错失率减半。这当然是个改进，但视cache行的大小而定，也许仍不是我们能够得到的最好结果。Core 2 处理器有个cache行大小为 64 byte的 L1d。实际的大小能够使用<code>sysconf (_SC_LEVEL1_DCACHE_LINESIZE)</code>在执行期查询、或是使用命令行的 <code>getconf</code> 工具程序（utility），以让程序能够针对特定的cache行大小编译。</p><p>以 <code>sizeof(double)</code> 为 8 来说，为了完全利用cache行，我们应该展开内部循环 8 次。继续这个想法，为了有效地使用 <code>res</code> 矩阵。即，为了同时写入 8 个结果，我们也该展开外部循环 8 次。我们假设这里的cache行大小为 64，但这个程序码也能在 32 bytecache行的系统上运作，因为cache行也会被 100% 利用。一般来说，最好在编译期像这样使用 <code>getconf</code> 工具程序来写死（hardcode）cache行大小：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">gcc -DCLS=$(getconf LEVEL1_DCACHE_LINESIZE) ...</span><br></pre></td></tr></table></figure><p>如果二进制文件应该是通用的，应该使用最大的cache行大小。使用非常小的 L1d 表示并非所有数据都能塞进cache，但这种处理器无论如何都不适合高效能程序。我们写出的程序码看起来像这样：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> SM (CLS / sizeof (double))</span></span><br><span class="line"><span class="keyword">for</span> (i = <span class="number">0</span>; i &lt; N; i += SM)</span><br><span class="line">  <span class="keyword">for</span> (j = <span class="number">0</span>; j &lt; N; j += SM)</span><br><span class="line">    <span class="keyword">for</span> (k = <span class="number">0</span>; k &lt; N; k += SM)</span><br><span class="line">      <span class="keyword">for</span> (i2 = <span class="number">0</span>, rres = &amp;res[i][j],</span><br><span class="line">           rmul1 = &amp;mul1[i][k]; i2 &lt; SM;</span><br><span class="line">           ++i2, rres += N, rmul1 += N)</span><br><span class="line">        <span class="keyword">for</span> (k2 = <span class="number">0</span>, rmul2 = &amp;mul2[k][j];</span><br><span class="line">             k2 &lt; SM; ++k2, rmul2 += N)</span><br><span class="line">          <span class="keyword">for</span> (j2 = <span class="number">0</span>; j2 &lt; SM; ++j2)</span><br><span class="line">            rres[j2] += rmul1[k2] * rmul2[j2];</span><br></pre></td></tr></table></figure><p>这看起来很可怕。在某种程度上是的，仅仅是因为它包含了一些技巧。最明显的变化是我们现在有六个嵌套循环。外部循环以SM的间隔迭代（缓存行大小由<code>sizeof（double）</code>分割）。这将乘法分解成几个较小的问题，这些问题可以用更多的缓存局部性来处理。内部循环迭代外部循环的缺失索引。再次，有三个循环。这里唯一棘手的部分是k2和j2循环的顺序不同。这样做是因为在实际计算中，只有一个表达式依赖于k2，而两个依赖于j2。</p><p>这里其余的复杂性来自这样一个事实，即gcc在优化数组索引时并不十分聪明。通过引入额外变量rres、rmul1和rmul2，可能从内部循环中提取公共表达式来优化代码。C和C++语言的默认混淆现象规则无助于编译器做出这些决定（除非使用限制，否则所有指针访问都是混淆现象的潜在来源）。这就是为什么Fortran仍然是数值编程的首选语言：它使编写快速代码变得更容易<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>。</p><figure><table><tr><th></th><th>原始</th><th>转置</th><th>子矩阵</th><th>向量化</th></tr><tr><th>周期数</th><td>16,765,297,870</td><td>3,922,373,010</td><td>2,895,041,480</td><td>1,588,711,750</td></tr><tr><th>相对值</th><td>100%</td><td>23.4%</td><td>17.3%</td><td>9.47%</td></tr></table><figcaption>表 6.2：矩阵乘法计时</figcaption></figure><p>所有努力所带来的成果能够在表 6.2 看到。借由避免复制，我们增加额外的 6.1% 效能。此外，我们不需要任何额外的memory。只要结果矩阵也能塞进memory，输入矩阵可以是任意大小的。这是我们现在已经达成的一个通用解法的一个必要条件。</p><p>在表 6.2 中还有一栏没有被解释过。大多现代处理器现今包含针对向量化（vectorization）的特殊支援。经常被标为多媒体扩充，这些特殊指令能够同时处理 2、4、8、或者更多值。这些经常是 SIMD（单指令多数据，Single Instruction, Multiple Data）操作。通过其他操作以正确的形式获得数据。英特尔处理器提供的SSE2指令可以在一次操作中处理两个<code>double</code>值。指令参考手册列出提供对这些 SSE2 指令存取的 intrinsic 函数。若是使用这些 intrinsic 函数，程序执行会变快 7.3%（相对于原始代码）。结果是程序运行时间为原始代码的10%。翻译成人们认识的数字，我们从 318 MFLOPS 提升到 3.35 GFLOPS。由于我们在这里仅对memory的影响有兴趣，程序的原始代码被放到 A.1 节。</p><p>应该注意的是，在最后一个版本的代码中，我们仍然有一些mul2的缓存问题；预取仍然不起作用。但是如果没有转置矩阵，这是无法解决的。也许缓存预取单元会变得更聪明来识别模式，那么就不需要额外的改变了。不过，以一个 2.66 GHz 处理器上的单线程程序而言，3.19 GFLOPS 并不差。</p><p>我们在矩阵乘法的例子中优化的是被加载cache line的使用。cache line的所有字节总是被用到。我们只是确保它们在cache line被逐出之前被使用。这当然是一个特殊情况。</p><p>更常见的情况是，数据结构填充一个或多个缓存行，而程序在任何时候只使用几个成员。在图3.11中，我们已经看到了大size结构在只有一些成员被用到时的影响。</p><figure><img data-src="/posts/8bd607ed/figure-6.2.webp" alt="图 6.2：散布在多个cache行中"><figcaption>图 6.2：散布在多个cache行中</figcaption></figure><p>图6.2显示了使用现在已熟知的程序执行另一组基准测试的结果。这次添加了相同列表元素的两个值。一种情况下，两个元素都在相同的缓存行中；另一种情况下，一个元素在列表元素的第一个缓存行中，第二个在最后一个缓存行中。该图显示了我们正在经历的性能衰减。</p><p>不出所料，在所有情况下，如果工作集能放进 L1d，都不会有负面影响。一旦L1d不再足够，就会通过在进程中使用两条cache line而不是一条来支付损失。红线显示了列表在内存中顺序排列时的数据。我们看到通常的两步模式：当L2缓存足够时，大约有17%的损失，当必须使用主存时，大约有27%的损失。</p><p>在随机内存访问的情况下，相对的数据看起来有点不同。适合L2的工作集的性能衰减在25%到35%之间。再往后，它下降到大约10%。这不是因为损失变得更小，而是因为实际的内存访问变得不成比例地昂贵。数据还显示，在某些情况下，元素之间的距离确实很重要。Random 4 CLs曲线显示了更高的损失，因为使用了第一条和第四条cache line。</p><p>查看与cache line相比较的数据结构布局的一个简单方法是使用pahole程序（参见<a href="#refer-anchor-4">4</a>）。这个程序检查二进制中定义的数据结构。取一个包含这个定义的程序：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">foo</span> &#123;</span></span><br><span class="line">  <span class="type">int</span> a;</span><br><span class="line">  <span class="type">long</span> fill[<span class="number">7</span>];</span><br><span class="line">  <span class="type">int</span> b;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>当在64位机器上编译时，pa-hole的输出包含（除其他外）图6.3所示的输出。这个输出告诉我们很多。首先，它显示数据结构使用了不止一条cache line。该工具假设当前使用的处理器的cache line大小，但是这个值可以使用命令行参数覆盖。特别是在结构的大小刚刚超过cache line的限制，并且分配了许多这种类型的对象的情况下，寻找一种压缩该结构体的方法是有意义的。也许一些元素可以有更小的类型，或者一些字段实际上是标志，可以用单个位来表示。</p><figure><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">foo</span> &#123;</span></span><br><span class="line">      <span class="type">int</span>                        a;                    <span class="comment">/*     0     4 */</span></span><br><span class="line"></span><br><span class="line">      <span class="comment">/* XXX 4 bytes hole, try to pack */</span></span><br><span class="line"></span><br><span class="line">      <span class="type">long</span> <span class="type">int</span>                   fill[<span class="number">7</span>];              <span class="comment">/*     8    56 */</span></span><br><span class="line">      <span class="comment">/* --- cacheline 1 boundary (64 bytes) --- */</span></span><br><span class="line">      <span class="type">int</span>                        b;                    <span class="comment">/*    64     4 */</span></span><br><span class="line">&#125;;<span class="comment">/* size: 72, cachelines: 2 */</span></span><br><span class="line">  <span class="comment">/* sum members: 64, holes: 1, sum holes: 4 */</span></span><br><span class="line">  <span class="comment">/* padding: 4 */</span></span><br><span class="line">  <span class="comment">/* last cacheline: 8 bytes */</span></span><br></pre></td></tr></table></figure><figcaption>图 6.3：pahole 执行的输出</figcaption></figure><p>在这个例子中，压缩很容易，程序也暗示了这一点。输出显示在第一个元素后面有一个四个字节的洞。这个洞是由结构体对齐要求和填充元素造成的。很容易看到元素<code>b</code>，它的大小为四个字节（由行尾的4表示），完全适合间隙(gap)。在这种情况下，结果是间隙(gap)不再存在，数据结构塞得进一条cache line。pahole工具可以自己执行这种结构体最佳化。如果使用<code>--reorganization</code>参数，并在命令行的末尾添加结构体名称，工具的输出就是最佳化的结构和使用的cache line。除了移动元素来填充间隙之外，该工具还可以优化bit 字段，并合并填充(padding)和洞。有关更多详细信息，请参见<a href="#refer-anchor-4">4</a>。</p><p>当然，拥有一个足够大的洞来容纳末尾元素是理想的情况。为了使这种选项有用，需要对象本身与缓存行对齐。我们稍后会谈到这一点。</p><p>pahole 输出也能够轻易看出元素是否必须被重新排列，以令那些一起用到的元素也会被储存在一起。使用 pahole 工具，很容易就能够确定哪些元素要在同个cache行，而不是必须在重新排列元素时才能达成。这并不是一个自动的过程，但这个工具能帮助很多。</p><p>各个结构元素的位置、以及它们被使用的方式也很重要。如同我们已经在 3.5.2 节看到的，晚到cache line的关键word的程序效能是很糟的。这表示一位程序开发者应该总是遵循下列两条原则：</p><ol><li>总是将最可能为关键word的结构元素移到结构的开头。</li><li>当访问数据结构时，访问顺序不受情况决定，按照结构中定义的顺序访问元素</li></ol><p>以小结构而言，这表示元素应该以它们可能被存取的顺序排列。这必须以灵活的方式处理，以允许其它像是填充，洞之类的优化也能被使用。对于较大的资料结构，每个cache line大小的区块应该遵循这些原则来排列。</p><p>但是，如果对象本身没有按预期对齐，就不值得花时间来重新排列它。对象的对齐由数据类型的对齐要求决定。每个基本类型都有自己的对齐要求。对于结构体类型，其任何元素中的最大对齐要求决定了结构体的对齐。这几乎总是小于cache line大小。这意味着即使结构体的成员被排列成塞得进同一个cache line，分配的对象也可能没有与cache line大小匹配的对齐方式。有两种方法可以确保对象具有在设计结构布局时使用的对齐:</p><p><strong>方法一</strong> 可以根据明确的对齐要求分配对象。对于动态分配，调用<code>malloc</code>只会以相符于最严格的标准类型（通常是<code>long Double</code>）的对齐来分配对象。不过，使用 <code>posix_memalign</code> 请求较高的对齐也是可能的。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;stdlib.h&gt;</span></span></span><br><span class="line"><span class="type">int</span> <span class="title function_">posix_memalign</span><span class="params">(<span class="type">void</span> **memptr,</span></span><br><span class="line"><span class="params">                   <span class="type">size_t</span> align,</span></span><br><span class="line"><span class="params">                   <span class="type">size_t</span> size)</span>;</span><br></pre></td></tr></table></figure><p>该函数将指向新分配内存的指针存储在memptr指向的指针变量中。内存块的大小为<code>size</code>字节，并在<code>align</code>字节边界上对齐。</p><p>对于编译器分配的对象(在 <code>.data</code>、<code>.bss</code> 等和堆栈上)，可以使用变量属性(attribute):</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">strtype</span> <span class="title">variable</span></span></span><br><span class="line"><span class="class">    __<span class="title">attribute</span>((<span class="title">aligned</span>(64)));</span></span><br></pre></td></tr></table></figure><p>在这个情况下，不管 <code>strtype</code> 结构的对齐需求为何，<code>variable</code> 都会在 64 byte边界上对齐。这也适用于全局变量和自动变量。</p><p>对于数组，这种方法并不像人们期望的那样工作。除非每个数组元素的大小是对齐值的倍数，否则只有数组的第一个元素会对齐。这也意味着每个变量都必须得到适当的标注。<code>posix_memalign</code>的使用也不是完全免费的，因为对齐要求通常会导致碎片和/或更高的内存消耗。</p><p><strong>方法二</strong> 可以使用type属性更改用户定义类型的对齐要求：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">strtype</span> &#123;</span></span><br><span class="line">...members...</span><br><span class="line">&#125; __attribute((aligned(<span class="number">64</span>)));</span><br></pre></td></tr></table></figure><p>这将导致编译器以适当的对齐方式分配所有对象，包括数组。不过，程序员必须注意为动态分配的对象请求适当的对齐方式。这里必须再次使用<code>posix_memalign</code>。使用gcc提供的对齐运算符并将值作为第二个参数传递给<code>posix_memalign</code>很容易。</p><p>本节前面提到的多媒体扩展几乎总是要求内存访问对齐。即，对于16字节的内存访问，地址应该是16字节对齐的。x86和x86-64处理器具有特殊的内存操作变体，可以处理未对齐的访问，但速度较慢。对于大多数需要对所有内存访问进行完全对齐的RISC架构来说，这种硬对齐要求并不是什么新鲜事。即使架构支持未对齐的访问，这有时也比使用适当的对齐慢，特别是如果不对齐导致加载或存储使用两条cache line 而不是一条。</p><figure><img data-src="/posts/8bd607ed/figure-6.4.webp" alt><figcaption>图 6.4：非对齐访问的间接成本</figcaption></figure><p>图 6.4 显示非对齐memory访问的影响。现在众所周知的测试是在访问内存（顺序或随机）时增加数据元素的，一次是对齐的列表元素，一次是故意不对齐的元素。该图显示了程序由于未对齐访问而导致的减速。顺序访问情况的影响比随机情况更显著，因为在后一种情况下，未对齐访问的成本被通常较高的内存访问成本部分隐藏。在顺序情况下，对于适合L2缓存的工作集大小，减速约为300%。这可以用L1缓存的有效性降低来解释。一些递增操作现在触及两条cache line，现在开始对列表元素的工作通常需要读取两条cache line。L1和L2之间的连接太拥挤了。</p><p>对于非常大的工作集，未对齐访问的影响仍然是20%到30%——考虑到这些规模的工作集的对齐访问时间很长，这是一个很大的影响。这张图应该表明对齐必须认真对待。即使架构支持未对齐访问，这也不能被视为“它们和对齐访问一样好”。</p><p>但是，这些对齐要求会产生一些影响。如果自动变量有对齐要求，编译器必须确保在所有情况下都满足它。这并不简单，因为编译器无法控制调用点（call site）与它们处理堆栈的方式。这个问题可以通过两种方式处理：</p><ol><li>产生的程序主动地对齐堆栈，必要时插入间隔。这需要程序检查对齐、建立对齐、并在之后还原对齐。</li><li>要求所有的调用点都将堆栈对齐。</li></ol><p>所有常用的应用程序二进制接口（ABI）都遵循第二条路线。如果调用者违反规则并且需要在被调用者中对齐，程序可能会失败。不过，保持对齐不变并不是免费的。</p><p>函数中使用的堆栈帧的大小不一定是对齐的倍数。这意味着如果从该堆栈帧调用其他函数，则需要填充。最大的区别在于，在大多数情况下，编译器知道堆栈帧的大小，因此，它知道如何调整堆栈指针以确保从该堆栈帧调用的任何函数的对齐。事实上，大多数编译器会简单地将堆栈帧大小四舍五入并完成它。</p><p>如果使用可变长度数组(VLA)或alloca，这种简单方法是不可能处理对齐的。在这种情况下，堆栈帧的总大小只有在运行时才知道。在这种情况下，可能需要主动对齐控制，从而使生成的代码（稍微）变慢。</p><p>在某些架构上，只有多媒体扩展需要严格对齐；这些架构上的堆栈总是针对正常数据类型进行最小对齐，通常分别针对32位和64位架构进行4或8字节对齐。在这些系统上，强制对齐会产生不必要的成本。这意味着，在这种情况下，如果我们知道它永远不会被依赖，我们可能希望摆脱严格的对齐要求。没有多媒体操作的尾函数（那些不调用其他函数的函数）不需要对齐。只调用不需要对齐的函数的函数也不用。如果可以确定足够大的函数集，程序可能希望放宽对齐要求。对于x86二进制文件，gcc支持宽松的堆栈对齐要求:<code>-mpreferred-stack-boundary=2</code>。</p><p>若是这个选项（option）的值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.10903em">N</span></span></span></span>，堆栈对齐需求将会被设为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>N</mi></msup></mrow><annotation encoding="application/x-tex">2^{N}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.10903em">N</span></span></span></span></span></span></span></span></span></span></span></span> byte。所以，若是使用 2 为值，堆栈对齐需求就被从预设值(16 byte)降低成只有4byte。在大多情况下，这表示不需额外的对齐操作，因为普通的堆栈推入(push)与弹出(pop)操作无论如何都是在4 byte边界上操作的。这个机器特定的选项能够帮忙减少程序大小，也能够提升执行速度。但它无法被套用到许多其它的架构上。即使对于x86-64，一般来说也不适用，因为 x86-64 ABI 要求在 SSE 暂存器中传递浮点数参数，而 SSE 指令需要完整的 16 byte对齐。然而，只要能够使用这个选项，就能造成明显的差别。</p><p>结构元素的有效放置和对齐并不是影响缓存效率的数据结构的唯一方面。如果使用结构数组，整个结构定义会影响性能。回想一下图 3.11 的结果：在这种情况下，我们在数组元素中增加了未使用的数据量。结果是预取的效率越来越低，对于大型数据集，程序变得不那么有效。</p><p>对于大型工作集，尽可能使用可用的缓存很重要。为了实现这一点，可能需要重新排列数据结构。虽然程序员更容易将概念上属于同一数据结构的所有数据放在一起，但这可能不是获得最大性能的最佳方法。假设我们有如下数据结构：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">order</span> &#123;</span></span><br><span class="line">  <span class="type">double</span> price;</span><br><span class="line">  <span class="type">bool</span> paid;</span><br><span class="line">  <span class="type">const</span> <span class="type">char</span> *buyer[<span class="number">5</span>];</span><br><span class="line">  <span class="type">long</span> buyer_id;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure><p>进一步假设这些记录存储在一个大数组中，一个经常运行的作业将所有未偿账单的预期付款加起来。在这种情况下，用于buyer和buyer_id字段的内存被不必要地加载到缓存中。从图3.11中的数据来看，程序的性能将比它可能的性能差5倍。</p><p>最好将<code>order</code>数据结构分成两块，将前两个字段存储在一个结构中，将其他字段存储在其他地方。这种变化肯定会增加程序的复杂性，但性能提升可能会证明这种成本是合理的。</p><p>最后，让我们考虑另一种缓存使用优化，虽然它也适用于其他缓存，但主要体现在L1d访问中。如图3.8所示，缓存关联性的增加有利于正常的操作。缓存越大，关联性通常越高。L1d cache太大，以致于无法为全关联式，但又没有足够大到要拥有跟 L2 cache一样的关联度。若是工作集中的许多对象属于相同的cache集，这可能会是个问题。如果这导致由于过于使用一组集合而造成逐出，即使大多cache都没被用到，程序还是可能会受到延迟。这些cache错失有时被称为<strong>冲突性丢失（conflict miss）</strong>。由于 L1d 定址使用虚拟地址，这实际上是能够受程序开发者控制的。如果一起被用到的变数也储存在一块儿，那么它们落入同一集合的可能性就会最小化。图 6.5 显示了问题发生的速度。</p><figure><img data-src="/posts/8bd607ed/figure-6.5.webp" alt><figcaption>图 6.5：cache关联度影响</figcaption></figure><p>在这张图中，现在熟悉的、使用 <code>NPAD</code>=15 的 Follow<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> 。测试是以特殊的配置来量测的。X 轴是两个列表元素之间的距离，以空列表元素为单位量测。换句话说，距离为 2 代表下一个元素的地址是在前一个元素的 128 byte之后。所有元素都以相同的距离在虚拟memory空间中摆放。Y 轴显示列表的总长度。仅会使用 1 至 16 个元素，代表工作集总大小为 64 至 1024 byte。Z 轴显示寻访每个列表元素所需的平均周期数。</p><p>图中显示的结果并不令人惊讶。如果使用很少的元素，所有数据都适合L1d，每个列表元素的访问时间只有3个周期。几乎所有列表元素的排列都是如此：虚拟地址被很好地映射到L1d插槽，几乎没有冲突。有两个（在这张图中）特殊的距离值，情况不同。如果距离是4096字节的倍数（即64个元素的距离），并且列表的长度大于8，则每个列表元素的平均周期数急剧增加。在这种情况下，所有条目都在同一个集合中，一旦列表长度大于关联性，条目就会从L1d流出，并且必须在下一轮从L2重新读取。这导致每个列表元素大约10个周期的成本。</p><p>通过这张图，我们可以确定所使用的处理器有一个关联性为8的L1d缓存，总大小为32kB。这意味着如果有必要，可以使用测试来确定这些值。对于L2缓存，可以测量同样的影响，但是，这里，它更复杂，因为L2缓存使用物理地址进行索引，而且它要大得多。</p><p>程序员希望将这些数据视为集合关联性是值得关注的指标。在现实世界中，将数据布局在2次方的边界上经常发生，但这正是很容易导致上述影响和性能下降的情况。未对齐的访问会增加冲突未命中的可能性，因为每次访问都可能需要额外的缓存行。</p><figure><img data-src="/posts/8bd607ed/figure-6.6.webp" alt><figcaption>图 6.6：AMD 上 L1d 的 Bank 地址</figcaption></figure><p>如果执行这种优化，另一种相关的优化也是可能的。AMD的处理器至少将L1d实现为几个单独的bank。L1d每个周期可以接收两个数据字，但前提是两个字都存储在不同的bank或具有相同索引的bank中。bank地址被编码为虚拟地址的低位，如图6.6所示。如果一起使用的变量也一起存储，那么它们在不同bank或具有相同索引的同一bank中的可能性很高。</p><h3 id="优化一级指令缓存访问">优化一级指令缓存访问</h3><p>准备有效使用 L1i 的程序码需要与有效使用 L1d 类似的技术。不过，问题是，程序开发者通常不会直接影响 L1i 的使用方式，除非他在汇编程序中编写代码，否则程序语法通常不会直接影响L1i的使用方式。若是使用编译器，程序开发者能够透过引导编译器建立更好的程序布局，来间接地决定 L1i 的使用。</p><p>代码的优点是跳转之间是线性的。在这些时期，处理器可以有效地预取内存。跳转打破这个美好的想像，因为:</p><ul><li>跳跃目标可能不是静态确定的；</li><li>即使它是静态的，如果它错过了所有缓存，内存获取也可能需要很长时间。</li></ul><p>这些问题造成执行中的停顿，可能严重地影响效能。这即是为何现今的处理器在分支预测（branch prediction，BP）上费尽心思的原因。高度特制化的 BP 单元试著尽可能远在跳跃之前确定跳跃的目标，使得处理器能够开始将新的位置的指令载入到cache中。它们使用静态与动态规则、而且越来越擅于判定执行中的模式。</p><p>尽快将数据放入缓存对于指令缓存来说更加重要。如第3.1节所述，指令必须在执行之前进行解码，为了加快速度（在x86和x86-64上很重要），指令实际上以解码形式缓存，而不是从内存中读取的字节/字形式。</p><p>为了实现最佳的L1i使用，程序员至少应该注意代码生成的以下方面：</p><ul><li>尽可能减少代码占用。这必须与循环展开和内联等优化相平衡。</li><li>代码执行应该是线性的，没有气泡<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>。</li><li>在有意义的时候对齐代码。</li></ul><p>我们现在将研究一些可用于帮助根据这些方面优化程序的编译器技术。</p><p>编译器可以选择启用优化级别；也可以单独启用特定的优化。许多在高优化级别启用的优化(gcc的-O2和-O3)处理循环优化和函数内联。一般来说，这些都是很好的选择。如果以这些方式优化的代码占程序总执行时间的很大一部分，则可以提高整体性能。特别是函数内联，允许编译器在同一时间优化更大的代码块，这反过来又可以生成更好地开发处理器管道架构的机器代码。当程序的较大部分可以被视为单个单元时，代码和数据的处理（通过死代码消除或值范围传播等）效果更好。</p><p>较大的代码大小意味着对L1i（以及L2和更高级别）缓存的压力更大。这可能会导致性能下降。较小的代码可能会更快。幸运的是，gcc有一个优化选项来指定这一点。如果使用-os，编译器将针对代码大小进行优化。已知会增加程序大小的最佳化会被关掉。使用此选项通常会产生令人惊讶的结果。特别是如果编译器不能真正利用循环展开和内联，则此选项是一个巨大的胜利。</p><p>内联也可以单独控制。编译器有指导内联的启发式和限制；这些限制可以由程序员控制。<code>-finnline-limited</code>选项指定函数必须有多大才能被认为太大而无法内联。如果一个函数在多个地方被调用，在所有地方内联它会导致代码大小爆炸。但是还有更多。假设一个函数<code>inlcand</code>在两个函数f1和f2中被调用。函数f1和f2本身是按顺序调用的。</p><figure><table><tr><td><pre><code>start f1
  code f1
  inlined inlcand
  more code f1
end f1
<p>start f2<br>
code f2<br>
inlined inlcand<br>
more code f2<br>
end f2</p></code></pre></td><br><td><pre><code>start inlcand<br>
code inlcand<br>
end inlcand<p></p>
<p>start f1<br>
code f1<br>
end f1</p>
<p>start f2<br>
code f2<br>
end f2</p></code></pre></td><br></tr><p></p></table><figcaption>表 6.3：行内展开 Vs 没有行内展开</figcaption></figure><p>表6.3显示了在两个函数中没有内联和内联的情况下生成的代码。如果函数inlcand在f1和f2中都被内联，则生成的代码的总大小为 size <code>f1</code> + size <code>f2</code> + <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>2</mn><mo>×</mo></mrow><annotation encoding="application/x-tex">2\times</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7278em;vertical-align:-.0833em"></span><span class="mord">2</span><span class="mord">×</span></span></span></span> size <code>inlcand</code>。如果没有发生内联，则总大小减少 size <code>inlcand</code>。如果f1和f2相继调用，则需要更多的L1i和L2缓存。另外：如果<code>inlcand</code> 没有内联，代码可能仍在L1i中，并且不必再次解码。另外：分支预测单元可能会更好地预测跳转，因为它已经看到了代码。如果编译器默认的内联函数大小上限不适合程序，则应该降低它。</p><p>然而，在某些情况下，内联总是有意义的。如果一个函数只被调用一次，它还不如被内联。这给了编译器执行更多优化的机会（比如值范围传播，这可能会显著改进代码）。这种内联可能会受到选择限制的阻碍。对于这种情况，gcc有一个选项来指定一个函数总是内联的。添加<code>always_inline</code>函数属性会指示编译器完全按照名称所暗示的去做。</p><p>在相同的上下文中，如果一个函数足够小，但永远不应该内联，则可以使用<code>noinline</code>函数属性。如果经常从不同的地方调用它们，即使对于小函数，使用此属性也有意义。如果L1i内容可以重用，并且总体占用空间减少，这通常可以弥补额外函数调用的额外成本。分支预测单元现在非常好。如果内联可以导致更积极的优化，事情看起来就不同了。这必须根据具体情况来决定。</p><p>如果总是使用内联代码，<code>always_inline</code>属性工作得很好。但是如果不是这样呢？如果内联函数只是偶尔调用怎么办？</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">void</span> <span class="title function_">fct</span><span class="params">(<span class="type">void</span>)</span> &#123;</span><br><span class="line">  ... code block A ...</span><br><span class="line">  <span class="keyword">if</span> (condition)</span><br><span class="line">    inlfct()</span><br><span class="line">  ... code block C ...</span><br></pre></td></tr></table></figure><p>为这样的代码序列生成的代码通常与源的结构相匹配。这意味着首先是代码块A，然后是条件跳转，如果条件评估为false，则向前跳转。接下来是为内联<code>inlfct</code>生成的代码，最后是代码块C。这看起来很合理，但有一个问题。</p><p>如果条件经常为假，则执行不是线性的。中间有一大块未使用的代码，这不仅由于预取而污染L1i，还会导致分支预测问题。如果分支预测是错误的，条件表达式可能非常无效。</p><p>这是一个普遍的问题，而不是只内联函数。每当使用条件执行并且它是不平衡的（即，表达式通常导致一个结果而不是另一个结果）时，就有可能出现错误的静态分支预测，从而在管道中产生气泡。这可以通过告诉编译器将不太经常执行的代码移出主代码路径来防止。在这种情况下，为if语句生成的条件分支将跳转到顺序错误的地方，如下图所示。</p><figure><img data-src="/posts/8bd607ed/figure-6.6.webp" alt></figure><p>上面的部分代表简单的代码布局。如果区域B，例如从上面的内联函数<code>inlfct</code>生成的，因为条件I跳过它而经常不执行，处理器的预取将拉入包含很少使用的块B的缓存行。使用块重新排序可以改变这一点，结果可以在图的下部看到。经常执行的代码在内存中是线性的，而很少执行的代码被移动到不影响预取和L1i效率的地方。</p><p>gcc提供了两种方法来实现这一点。首先，编译器可以在重新编译代码时考虑配置输出，并根据配置文件布局代码块。我们将在第7节中看到这是如何工作的。第二种方法是通过显式分支预测。gcc识别<code>__builtin_expect</code>：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">long</span> __builtin_expect(<span class="type">long</span> EXP, <span class="type">long</span> C);</span><br></pre></td></tr></table></figure><p>这个构造告诉编译器表达式EXP很可能具有值C。返回值是EXP。<code>__builtin_expect</code>用于条件表达式。在几乎所有情况下，它都会在布尔表达式的上下文中使用，在这种情况下，定义两个辅助宏要方便得多：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">define</span> unlikely(expr) __builtin_expect(!!(expr), 0)</span></span><br><span class="line"><span class="meta">#<span class="keyword">define</span> likely(expr) __builtin_expect(!!(expr), 1)</span></span><br></pre></td></tr></table></figure><p>然后可以将这些宏用作</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> (likely(a &gt; <span class="number">1</span>))</span><br></pre></td></tr></table></figure><p>如果程序员使用这些宏，然后使用<code>-freorder-block</code>优化选项，gcc将重新排序块，如上图所示。此选项使用<code>-O2</code>启用，但对<code>-O</code>禁用。还有另一个gcc选项来重新排序块<code>-freorder-blocks-and-partition</code>，但它的有用性有限，因为它不适用于异常处理。</p><p>至少在某些处理器上，小循环还有另一个很大的优势。英特尔酷睿2前端有一个特殊的功能，叫做循环流检测器（LSD）。如果一个循环不超过18条指令（没有一条是对子例程的调用），最多只需要4个16字节的解码器提取，最多有4个分支指令，并且执行超过64次，那么循环有时会被锁定在指令队列中，因此在再次使用循环时可以更快地使用。例如，这适用于通过外循环多次输入的小型内部循环。即使没有这种专门的硬件，紧凑的循环也有优势。</p><p>内联不是L1i优化的唯一方面。另一个方面是对齐，就像数据一样。有明显的区别：代码是一个主要是线性的blob，不能任意放置在地址空间中，也不能在编译器生成代码时直接受到程序员的影响。虽然程序员可以控制某些方面。将每条指令对齐没有任何意义。目标是让指令流是顺序的。所以对齐只在战略位置有意义。要决定在哪里添加对齐，有必要了解优势是什么。在缓存线的开头有一条指令<sup class="footnote-ref"><a href="#fn5" id="fnref5">[5]</a></sup>意味着缓存线的预取最大化。对于指令来说，这也意味着解码器更有效。很容易看出，如果执行缓存线末尾的指令，处理器必须准备好读取新的缓存线并对指令进行解码。有些事情可能会出错（例如缓存线未命中），这意味着平均而言，缓存线末尾的指令执行效率不如开头的指令。</p><p>将此与后续推论相结合，即如果控制只是转移到有问题的指令（因此预取无效），问题最严重，我们得出最终结论，代码对齐最有用的地方:</p><ul><li>在函数的开头；</li><li>在仅会通过跳跃到达的基础区块的开头；</li><li>在某种程度上，在循环的开始。</li></ul><p>在前两种情况下，对齐成本很低。执行在新位置继续，如果我们选择它在缓存行的开头，我们会优化预取和解码。<sup class="footnote-ref"><a href="#fn6" id="fnref6">[6]</a></sup>。编译器通过插入一系列非操作指令来填补对齐代码造成的空白来实现这种对齐。这种“死代码”占用一点空间，但通常不会损害性能。</p><p>第三种情况略有不同：对齐每个循环的开始可能会产生性能问题。问题是循环的开始通常会按顺序跟随其他代码。如果情况不是很幸运，前一条指令和对齐的循环开始之间会有一个间隙。与前两种情况不同，这个间隙不能完全消失。在前一条指令执行后，必须执行循环中的第一条指令。这意味着，在前一条指令之后，要么必须有许多无操作指令来填补空白，要么必须无条件跳转到循环的开始。这两种可能性都是免费的。特别是如果循环本身不经常执行，无操作或跳转可能会花费不止一个通过对齐循环节省的成本。</p><p>程序员可以通过三种方式影响代码的对齐。显然地，若是程序是以汇编语言撰写，其中的函数与所有的指令都能够被明确地对齐。汇编器为所有架构提供了<code>.align</code> 伪操作来做到这一点。对于高级语言，必须告知编译器对齐要求。与数据类型和变量不同，这在源代码中是不可能的。相反，使用编译器选项：<code>-falign-functions=N</code>。这个选项命令编译器将所有函数对齐到下一个大于 <code>N</code> 的二的幂次的边界。这表示会产生一个至多 <code>N</code> byte的间隔。对小函数而言，使用一个很大的 <code>N</code> 值是个浪费。对于很少执行的代码也是如此。后者在包含流行和不太流行接口的库中经常发生。明智地选择选项值可以通过避免对齐来加快速度或节省内存。通过使用一个作为N的值或使用<code>-fno-align-functions</code>选项来关闭所有对齐。</p><p>上面第二种情况的对齐方式(基本块的开头没有按顺序到达)可以用不同的选项来控制：<code>-falign-jumps=N</code>。所有其它的细节都相同，关于浪费memory的警告也同样适用。</p><p>第三种情况也有它自己的选项：<code>-falign-loops=N</code>。再一次，同样的细节与警告都适用。除了这里，如前所述，对齐是以运行时成本为代价的，因为如果顺序到达对齐的地址，则必须执行无操作或跳转指令。</p><p>gcc 还知道一个用来控制对齐的选项，在这里提起它仅是为了完整起见。<code>-falign-labels</code> 对齐了程序中的每个单一标签(基本上是每个基础区块的开头)。除了一些例外状况之外，这都会让程序变慢，因而不该被使用。</p><h3 id="优化二级与更高级缓存访问">优化二级与更高级缓存访问</h3><p>关于1级缓存优化的所有内容也适用于2级和更高级别的缓存访问。最后一级缓存还有两个额外的方面:</p><ul><li>缓存未命中总是非常昂贵的。虽然L1未命中（希望）经常命中L2和更高级别的缓存，从而限制了惩罚，但显然最后一级缓存没有回退。</li><li>L2及更高版本的缓存通常由多个内核和/或超线程共享。因此，每个执行单元可用的有效缓存大小通常小于总缓存大小。</li></ul><p>为了避免缓存未命中的高成本，工作集大小应该与缓存大小匹配。如果数据只需要一次，这显然是不必要的，因为缓存无论如何都是无效的。我们谈论的是多次需要数据集的工作负载。在这种情况下，使用太大而无法放入缓存的工作集会产生大量缓存未命中，即使成功执行预取，也会减慢程序的速度。</p><p>即使数据集太大，程序也必须执行它的工作。程序员的工作是以最小化缓存miss的方式完成这项工作。对于最后一级缓存，可能是(就像L1缓存一样)在更小的部分上工作。这与表 6.2 的优化矩阵乘法非常相似。然而，一个区别是，对于最后一级缓存，要处理的数据块可以更大。如果也需要L1优化，代码会变得更加复杂。想象一个矩阵乘法，其数据集(两个输入矩阵和输出矩阵)无法同时进入最后一级缓存。在这种情况下，同时优化L1和最后一级缓存访问可能是合适的。</p><p>L1高速缓存线大小在许多代处理器中通常是恒定的；即使不是，差异也很小。仅仅假设较大的大小没有什么大问题。在高速缓存大小较小的处理器上，将使用两条或多条高速缓存线而不是一条。无论如何，硬编码高速缓存线大小并为此优化代码是合理的。</p><p>对于更高级别的缓存，如果程序应该是通用的，情况就不是这样了。这些缓存的大小可以有很大的不同。8个或更多的因素并不罕见。不可能假设较大的缓存大小为默认值，因为这意味着代码在所有机器上的性能都很差，除了那些缓存最大的机器。相反的选择也很糟糕：假设最小的缓存意味着丢弃87%或更多的缓存。这很糟糕；正如我们从图3.14中看到的，使用大型缓存会对程序的速度产生巨大影响。</p><p>这意味着代码必须根据缓存行大小动态调整自身。这是对程序的优化。这里我们只能说程序员应该正确计算程序的需求。不仅需要数据集本身，更高级别的缓存也用于其他目的；例如，所有执行的指令都是从缓存加载的。如果使用库函数，这种缓存使用量可能会增加很多。这些库函数可能还需要自己的数据，这进一步减少了可用内存。</p><p>一旦我们有了内存需求的公式，我们就可以将其与缓存大小进行比较。如前所述，缓存可能与多个其他内核共享。目前<sup class="footnote-ref"><a href="#fn7" id="fnref7">[7]</a></sup>，在没有硬编码知识的情况下获得正确信息的唯一方法是通过<code>/sys</code>文件系统。在表5.2中，我们已经看到了内核发布的关于硬件的内容。程序必须在目录查找: <code>/sys/devices/system/cpu/cpu*/cache</code>。</p><p>对于最后一级缓存。这可以通过该目录下 <code>level</code> 文件中的最高数值来识别。当目录被识别时，程序应该读取该目录中 <code>size</code> 文件的内容，并将数值除以<code>shared_cpu_map</code> 文件中位掩码的二进制数字值。</p><p>以这种方式计算的值是一个安全的下限。有时，程序更了解其他线程或进程的行为。如果这些线程被安排在共享缓存的核心或超线程上，并且已知缓存使用不会耗尽其在总缓存大小中的比例，那么计算的限制可能太低而不是最佳的。是否应该使用超过公平份额实际上取决于情况。程序编写者必须做出选择或必须允许用户做出决定。</p><h3 id="优化TLB使用">优化TLB使用</h3><p>TLB使用有两种优化。第一种优化是减少程序必须使用的页数。这会自动导致更少的TLB未命中。第二种优化是通过减少必须分配的高级目录表的数量来降低TLB查找的成本。更少的表意味着使用更少的内存，这可能会导致目录查找的更高缓存命中率。</p><p>第一个优化与最小化分页错误密切相关。我们将在第7.5节中详细讨论这个主题。虽然分页错误通常是一次性成本，但TLB未命中是一种永久的惩罚，因为TLB缓存通常很小，而且经常刷新。分页错误比TLB未命中贵几个数量级，但是，如果程序运行时间足够长，并且程序的某些部分执行得足够频繁，TLB未命中的成本甚至可能超过分页错误成本。因此，不仅要从分页错误的角度看待分页优化，还要从TLB未命中的角度看待分页优化。不同之处在于，虽然分页错误优化只需要对代码和数据进行分页范围的分组，但TLB优化要求在任何时候都尽可能少地使用TLB条目。</p><p>第二个TLB优化更难控制。必须使用的页面目录的数量取决于进程虚拟地址空间中使用的地址范围的分布。地址空间中位置的广泛变化意味着更多的目录。复杂的是地址空间布局随机化（ASLR）会导致这些情况。堆栈、DSO、堆和可能的可执行文件的加载地址在运行时是随机的，以防止机器的攻击者猜测函数或变量的地址。</p><p>只有当最高性能是关键时，ASLR才应该被关闭。额外目录的成本足够低，除了少数极端情况之外，其他情况下都不需要这个步骤。内核可以在任何时候执行的一种可能的优化是确保单个映射不跨越两个目录之间的地址空间边界。这将以最小的方式限制ASLR，但不足以大大削弱它。</p><p>程序开发者直接受此影响的唯一方式是在明确请求一个定址空间区域的时候。这会在以 MAP_FIXED 使用 mmap 的时候发生。以这种方式分配定址空间区域非常危险，人们几乎不会这么做。如果程序开发者使用上述方法且允许自由选取地址，则他们应该要知道最后一阶分页目录的边界，及适当挑选所请求的地址。</p><h2 id="预取">预取</h2><p>预取的目的是隐藏内存访问的延迟。当今处理器的命令流水线和乱序（out-of-order，简称OOO）执行能力可以隐藏一些延迟，但充其量只能用于访问缓存的访问。为了掩盖主存访问的延迟，命令队列必须非常长。一些没有OOO的处理器试图通过增加内核数量来弥补，但这是一笔糟糕的交易，除非所有正在使用的代码都并行化。预取可以进一步帮助隐藏延迟。处理器自行执行预取，由某些事件触发（硬件预取）或程序明确请求（软件预取）。</p><h3 id="硬件预取">硬件预取</h3><p>CPU启动硬件预取的触发，通常是以某种模式出现的两个或多个缓存未命中的序列。这些缓存未命中可能在缓存行的之前或之后。在旧的实现中，只识别相邻缓存行的缓存未命中。对于现代硬件，步幅也被识别，这意味着跳过固定数量的缓存行被识别为一种模式并得到适当的处理。</p><p>如果每一次缓存未命中都会触发一次硬件预取，这将对性能不利。随机内存访问模式，例如对全局变量的访问，非常常见，由此产生的预取将大大浪费FSB带宽。这就是为什么要启动预取，至少需要两次缓存未命中。今天的处理器都期望有不止一个内存访问流。处理器试图自动将每个缓存未命中分配给这样的流，如果达到阈值，则开始硬件预取。今天的CPU可以跟踪8到16个单独的流以用于更高级别的缓存。</p><p>负责模式识别的单元与各自的缓存相关联。L1d和L1i缓存可以有一个预取单元。L2缓存和更高版本很可能有一个预取单元。L2和更高版本的预取单元与使用相同缓存的所有其他内核和超线程共享。因此，8到16个单独流的数量很快就减少了。</p><p>预取有一个很大的缺点：它不能跨越分页边界。当人们意识到CPU支持需求分页时，原因应该是显而易见的。如果允许预取器跨越分页边界，访问可能会触发操作系统事件以使分页可用。这本身可能是不好的，尤其是对性能而言。更糟糕的是预取器不知道程序或操作系统本身的语义。因此，它可能会预取在实际上永远不会被请求的分页。这意味着预取器将预取超过处理器之前以可识别的模式访问的内存区域的边界。这不仅是可能，而且是非常可能。如果处理器–作为预取的副作用–触发了对这样一个分页的请求，操作系统甚至可能会在这种请求永远也不会发生时完全扔掉它的追踪纪录。</p><p>因此，重要的是要认识到，不管预取器在预测模式方面有多好，除非程序明确预取或从新分页读取，否则它将在分页边界处经历缓存未命中。这是优化数据布局的另一个原因，如第6.2节所述，通过将不相关的数据排除在外来最小化缓存污染。</p><p>由于这个分页限制，今天的处理器没有非常复杂的逻辑来识别预取模式。以仍占主导地位的 4k 分页大小而言，有意义的也就这么多。多年来，识别步幅的地址范围有所增加，但超越今天经常使用的512字节窗口可能没有多大意义。目前预取单元无法识别非线性访问模式。这种模式很可能是真正随机的，或者至少完全不重复的，尝试识别它们是没有意义的。</p><p>如果不小心触发了硬件预取，你只能做这么多。一种可能是尝试检测这个问题，并稍微改变一下数据与/或代码布局。这可能很难。可能会有特殊的本地化解决方案，例如在x86和x86-64处理器上使用ud2指令<sup class="footnote-ref"><a href="#fn8" id="fnref8">[8]</a></sup>。这个无法自己执行的指令是在一条间接的跳跃指令后被使用；它被作为指令获取器（fetcher）的一个信号使用，表示处理器不应浪费精力解码接下来的memory，因为执行将会在一个不同的位置继续。不过，这是个非常特殊的情况。在大部分情况下，必须要忍受这个问题。</p><p>可以完全或部分禁用整个处理器的硬件预取。在Intel处理器上，为此使用模型特定寄存器（MSR）（IA32 MISC ENABLE，许多处理器上为 bit 9；bit 19 仅禁用相邻的缓存行预取）。在大多数情况下，这必须在内核中发生，因为它是特权操作。若是数据分析显示，执行于系统上的一个重要的应用程序因硬件cache而遭受带宽占用和缓存过早驱逐，使用这个 MSR 是一种可能性。</p><h3 id="软件预取">软件预取</h3><p>硬件预取的优势在于不必调整程序。缺点如同方才描述的，存取模式必须很直观，而且预取无法横跨分页边界进行。因为这些原因，我们现在有更多可能性，软件预取它们之中最重要的。软件预取不需借由插入特殊的指令来修改原始码。某些编译器支援编译指示（pragma）以或多或少地自动插入预取指令。 在 x86 和 x86-64，intrinsic 函式会由编译器产生特殊的指令:</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;xmmintrin.h&gt;</span></span></span><br><span class="line"><span class="class"><span class="keyword">enum</span> _<span class="title">mm_hint</span></span></span><br><span class="line"><span class="class">&#123;</span></span><br><span class="line">  _MM_HINT_T0 = <span class="number">3</span>,</span><br><span class="line">  _MM_HINT_T1 = <span class="number">2</span>,</span><br><span class="line">  _MM_HINT_T2 = <span class="number">1</span>,</span><br><span class="line">  _MM_HINT_NTA = <span class="number">0</span></span><br><span class="line">&#125;;</span><br><span class="line"><span class="type">void</span> _mm_prefetch(<span class="type">void</span> *p,</span><br><span class="line">                  <span class="keyword">enum</span> _mm_hint h);</span><br></pre></td></tr></table></figure><p>程序可以在程序中的任何指针上使用<code>_mm_prefetch</code> intrinsic 函式。大多数处理器（当然是所有x86和x86-64处理器）忽略了无效指针导致的错误，这使得程序员的生活变得非常容易。如果传递的指针引用有效内存，预取单元将被命令将数据加载到缓存中，并在必要时驱逐其他数据。不必要的预取应该明确避免，因为这可能会降低缓存的有效性，并消耗内存带宽（在被逐出的cache行是脏的情况下，可能需要两个cache行）。</p><p>要与<code>_mm_prefetch</code> 内在函数一起使用的不同提示(hint)是由具体实现定义的。这意味着每个处理器版本可以（稍微）不同地实现它们。 通常可以说，对于包含缓存，<code>_MM_HINT_T0</code> 将数据提取到所有级别的缓存中，对于独占缓存，则提取到最低级别的缓存中。如果数据项在更高级别的缓存中，则将其加载到L1d中。<code>_MM_HINT_T1</code> 提示将数据拉入L2而不是L1d。如果有L3缓存，则 <code>_MM_HINT_T2</code>提示可以对其执行类似的操作。不过，这些都是细节，具体说明很弱，需要针对实际使用的处理器进行验证。一般来说，如果要立即使用数据，使用 <code>_MM_HINT_T0</code> 是正确的做法。当然，这需要L1d缓存大小足够大，以容纳所有预取的数据。如果立即使用的工作集的大小太大，那么将所有内容预取到L1d中是一个坏主意，应该使用另外两个提示。</p><p>第四种提示，<code>_MM_HINT_NTA</code>，允许告诉处理器特别处理预取的高速缓存行。NTA代表非暂存对齐(non-temporal aligned)，我们已经在第6.1节中解释过了。程序告诉处理器，应该尽可能避免用这些数据污染高速缓存，因为这些数据只使用了很短的时间。因此，对于包容性高速缓存，处理器可以在加载时避免将数据读入较低级别的高速缓存。当数据从L1d中被逐出时，数据不需要被推入L2或更高级别，而是可以直接写入内存。如果给出这个提示，处理器设计者可能还可以部署其他技巧。程序员必须小心使用这个提示：如果立即工作集大小太大，并且强制逐出使用NTA提示加载的高速缓存行，则将从内存中重新加载。</p><p>![](2020-11-08-What-Every-Programmer-Should-Know-About-Memory-3/figure-6.7.webp &quot;“图 6.7：使用预取的平均，NPAD=31&quot;”)</p><p>图6.7显示了使用现在熟知的指针追逐框架(pointer chasing framework)的测试结果。列表在内存中随机排列。与之前测试的不同之处在于，程序实际上在每个列表节点上花费了一些时间（大约160个周期）。正如我们从图3.15中的数据中了解到的，一旦工作集大小大于最后一级缓存，程序的性能就会受到严重影响。</p><p>我们现在可以尝试通过在计算之前发出预取请求来改善这种情况。也就是说，在每一轮循环中，我们预取一个新元素。列表中预取节点和当前正在处理的节点之间的距离必须仔细选择。考虑到每个节点在160个周期内被处理，并且我们必须预取两个缓存行（NPAD=31），五个列表元素的距离就足够了。</p><p>图6.7中的结果表明预取确实有帮助。只要工作集大小不超过最后一级缓存的大小（机器有512kB = 2<sup>19</sup>B 的 L2），数字都是相同的。预取指令不会增加可衡量的额外负担。一旦超过L2大小，预取就会节省50到60个周期，最多可达8%。使用预取不能隐藏所有的损失，但它确实有一点帮助。</p><p>AMD 在它们 Opteron 产品线的 <a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/AMD_10h">10h 家族</a>实现了另一个指令：<code>prefetchw</code>。在 Intel 这边迄今仍没有这个指令的等价物，也不能通过 intrinsic 使用。<code>prefetchw</code> 指令要求 CPU 将cache行预取到 L1 中，就如同其它预取指令一样。差异在于cache行会立即变成「M」状态。若是之后没有接著对cache行的写入，这将会是个不利之处。但若是有一或多次写入，它们将会被加速，因为写入操作不必改变cache状态 –– 其在cache行被预取时就被设好。这对于竞争的cache行尤为重要，其中在另一个处理器的cache中的cache行的一次普通的读取操作会先在两个cache中将状态改成「S」。</p><p>预取可能有比我们这里达到的微薄的 8% 还要更大的优势。但它是众所皆知地难以做得正确，特别是如果相同的二进制文件应该在各种机器上运行良好。CPU提供的性能计数器可以帮助编程人员分析预取。可以计数和采样的事件包括硬件预取、软件预取、有用/使用的软件预取、不同级别的缓存未命中等等。在第7.1节中，我们将介绍一些这样的事件。所有这些计数器都是机器特定的。</p><p>在分析程序时，应该首先查看缓存未命中。当有大量缓存未命中时，应该尝试为有问题的内存访问添加预取指令。这应该一次在一个地方完成。应该通过观察测量有用预取指令的性能计数器来检查每次修改的结果。如果这些计数器没有增加预取可能是错误的，它没有足够的时间从内存中加载，或者预取从缓存中驱逐仍然需要的内存。</p><p>今天的gcc能够在一种情况下自动发出预取指令。如果循环正在遍历数组，则可以使用以下选项:<code>-fprefetch-loop-arrays</code></p><p>编译器将弄清楚预取是否有意义，如果有，它应该往前看多远。对于小型数组，这可能是一个缺点，如果在编译时不知道数组的大小，结果可能会更糟。gcc手册警告说，好处在很大程度上取决于代码的形式，在某些情况下，代码实际上可能运行得更慢。程序员必须小心使用此选项。</p><h3 id="特殊的预取类型：猜测">特殊的预取类型：猜测</h3><p>现代处理器的OOO执行能力允许在指令不相互冲突的情况下移动指令。例如（这次使用IA-64作为示例）：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">st8        [r4] = 12</span><br><span class="line">add        r5 = r6, r7;;</span><br><span class="line">st8        [r18] = r5</span><br></pre></td></tr></table></figure><p>这段代码在寄存器 <code>r4</code> 指定的地址存储12，将寄存器 <code>r6</code> 和 <code>r7</code> 的内容相加并将其存储在寄存器 <code>r5</code> 中。最后，它将总和存储在寄存器 <code>r18</code> 指定的地址。这里的重点是add指令可以在第一条 <code>st8</code> 指令之前执行，或者与第一条st8指令同时执行，因为没有数据依赖关系。但是如果必须加载其中一个加数会发生什么呢？</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">st8        [r4] = 12</span><br><span class="line">ld8        r6 = [r8];;</span><br><span class="line">add        r5 = r6, r7;;</span><br><span class="line">st8        [r18] = r5</span><br></pre></td></tr></table></figure><p>额外的 <code>ld8</code> 指令从寄存器 <code>r8</code> 指定的地址中加载值。这个加载指令和接下来的 <code>add</code> 指令之间有明显的数据依赖关系(这就是为什么在指令之后有 <code>;;</code>）。这里的关键是新的 <code>ld8指令</code>——与 <code>add</code> 指令不同——不能移动到第一个<code>st8</code> 的前面。处理器在指令解码期间无法足够快地确定存储和加载是否冲突，即 <code>r4</code> 和 <code>r8</code> 是否可能具有相同的值。如果它们确实具有相同的值，<code>st8</code> 指令将确定加载到 <code>r6</code> 中的值。更糟糕的是，在载入未命中cache的情况下 <code>ld8</code> 还可能带来很大的延迟。IA-64架构支持这种情况的推测加载(speculative load)：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">ld8.a      r6 = [r8];;</span><br><span class="line">[... other instructions ...]</span><br><span class="line">st8        [r4] = 12</span><br><span class="line">ld8.c.clr  r6 = [r8];;</span><br><span class="line">add        r5 = r6, r7;;</span><br><span class="line">st8        [r18] = r5</span><br></pre></td></tr></table></figure><p>新的 <code>ld8.a</code> 和 <code>ld8.c.clr</code> 指令是一对的，并替换了前面代码中的 <code>ld8</code> 指令。<code>ld8.a</code> 指令是猜测式加载。该值不能直接使用，但处理器可以开始工作。当到达 <code>ld8.c.clr</code>指令时，内容可能已经被加载了（给定间隙中有足够数量的指令）。该指令的参数必须与 <code>ld8.a</code> 指令的参数匹配。如果前面的 <code>st8</code> 指令没有覆盖该值（即<code>r4</code>和 <code>r8</code>相同<sup class="footnote-ref"><a href="#fn9" id="fnref9">[9]</a></sup>），则无需做任何事情。猜测式加载完成了它的工作，加载的等待时间被隐藏。如果存储和加载发生冲突，<code>ld8.c.clr</code> 会从内存中重新加载该值，我们最终会得到正常的<code>ld8</code> 指令的语义。</p><p>猜测式加载还没有被广泛使用。但是正如这个例子所示，这是一种非常简单而有效的隐藏等待时间的方法。预取基本上是等价的，对于寄存器很少的处理器来说，猜测负载可能没有多大意义。猜测测负载有一个（有时很大的）优势，那就是直接将值加载到寄存器中，而不是缓存行中，在缓存行中，它可能会再次被逐出（例如，当线程被重新调度时）。如果可以使用猜测，就应该使用它。</p><h3 id="辅助线程">辅助线程</h3><p>当一个人试图使用软件预取时，他经常会遇到代码复杂性的问题。如果代码必须迭代一个数据结构（在我们的例子中是一个列表），他必须在同一个循环中实现两个独立的迭代：正常迭代完成工作，第二次迭代向前看，以使用预取。这很容易变得足够复杂，以至于很可能出错。</p><p>此外，有必要确定向前看多远。太少，内存将无法及时加载。太远，刚刚加载的数据可能会再次被驱逐。另一个问题是预取指令，尽管它们不会阻塞并等待内存加载，但需要时间。指令必须被解码，如果解码器太忙，这可能会很明显，例如，由于编写/生成的代码很好。最后，循环的代码大小增加。这降低了L1i效率。如果一个人试图通过连续发出多个预取请求来避免部分成本（以防第二次加载不依赖于第一次加载的结果），那么就会遇到未完成预取请求数量的问题。</p><p>另一种方法是完全分开执行正常操作和预取。这可以使用两个正常线程来发生。显然必须对线程进行调度，以便预取线程填充由两个线程访问的缓存。有两种特殊的解决方案值得一提：</p><ul><li>在同一内核上使用超线程(参见3.3.4中的超线程)。在这种情况下，预取可以进入L2(甚至L1d)。</li><li>使用比SMT线程更笨的线程，SMT线程除了预取和其他简单操作什么也做不了。这是处理器制造商可能会探索的一个选项。</li></ul><p>超线程的使用特别有趣。正如我们在3.3.4中看到的，如果超线程执行独立的代码，缓存的共享是一个问题。相反，如果一个线程被用作预取辅助线程，这不是问题。相反，这是个令人渴望的结果，因为最低层级的cache被预载。此外，由于预取线程大多处于空闲状态或等待内存，如果不必自己访问主存本身，另一个超线程的正常运行不会受到太大干扰。后者正是预取辅助线程所阻止的。</p><p>唯一棘手的部分是确保辅助线程不会运行得太远。它不能完全污染缓存，以至于再次驱逐最早的预取值。在Linux，使用<code>futex</code>系统调用<a href="#refer-anchor-7">7</a>或使用POSIX线程同步原语（成本稍高）可以轻松完成同步。</p><figure><img data-src="/posts/8bd607ed/figure-6.8.webp" alt><figcaption>图 6.8：使用辅助执行线程的平均，NPAD=31，NPAD=31</figcaption></figure><p>该方法的好处可以在图6.8中看到。这与图6.7中的测试相同，只是添加了额外的结果。新测试创建了一个额外的辅助线程，该线程提前运行大约100个列表条目，并读取（不仅仅是预取）每个列表元素的所有缓存行。在这种情况下，我们每个列表元素有两个缓存行（NPAD=31，在32位机器上，缓存行大小为64字节）</p><p>这两个线程被安排在同一个核心的两个超线程上。测试机器只有一个核心，但是如果有多个核心，结果应该是差不多的。我们将在第6.4.3节中介绍的affinity函数用于将线程绑定到适当的超线程。</p><p>为了确定操作系统知道哪两个（或更多）处理器是超线程，可以使用libNUMA 的 <code>NUMA_cpu_level_mask</code>接口(见附录D)。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="keyword">include</span> <span class="string">&lt;libNUMA.h&gt;</span></span></span><br><span class="line"><span class="type">ssize_t</span> <span class="title function_">NUMA_cpu_level_mask</span><span class="params">(<span class="type">size_t</span> destsize,</span></span><br><span class="line"><span class="params">                            <span class="type">cpu_set_t</span> *dest,</span></span><br><span class="line"><span class="params">                            <span class="type">size_t</span> srcsize,</span></span><br><span class="line"><span class="params">                            <span class="type">const</span> <span class="type">cpu_set_t</span>*src,</span></span><br><span class="line"><span class="params">                            <span class="type">unsigned</span> <span class="type">int</span> level)</span>;</span><br></pre></td></tr></table></figure><p>此接口可用于确定CPU的层次结构，因为它们通过缓存和内存连接。这里感兴趣的是对应于超线程的级别1。要在两个超线程上调度两个线程，可以使用libNUMA函数（为简洁起见，删除了错误处理）：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">cpu_set_t</span> self;</span><br><span class="line">NUMA_cpu_self_current_mask(<span class="keyword">sizeof</span>(self),</span><br><span class="line">                           &amp;self);</span><br><span class="line"><span class="type">cpu_set_t</span> hts;</span><br><span class="line">NUMA_cpu_level_mask(<span class="keyword">sizeof</span>(hts), &amp;hts,</span><br><span class="line">                    <span class="keyword">sizeof</span>(self), &amp;self, <span class="number">1</span>);</span><br><span class="line">CPU_XOR(&amp;hts, &amp;hts, &amp;self);</span><br></pre></td></tr></table></figure><p>执行这段代码后，我们有两个CPUbit集。<code>self</code> 可以用来设置当前线程的亲和性，<code>hts</code>中的掩码可以用来设置辅助线程的亲和性。理想情况下，这应该发生在线程创建之前。在第6.4.3节中，我们将介绍设置亲和性的接口。如果没有可用的超线程，<code>NUMA_cpu_level_mask</code>函数将返回1。这可以用作避免这种优化的标志。</p><p>这个基准测试的结果可能令人惊讶（也可能不是）。如果工作集适合L2，帮助线程的开销会降低10%到60%的性能（主要是在低端，再次忽略最小的工作集大小，噪音太高）。这应该是意料之中的，因为如果所有数据都已经在L2缓存中，预取帮助线程只使用系统资源而不会对执行做出贡献。</p><p>但是，一旦L2大小不够用，情况就会发生变化。预取辅助线程有助于减少大约25%的运行时间。我们仍然看到上升曲线，仅仅是因为预取的处理速度不够快。不过，主线程执行的算术运算和辅助线程的内存加载操作确实是相辅相成的。资源冲突最小，这导致了这种协同效应。</p><p>这个测试的结果应该可以转移到许多其他情况下。由于缓存污染，超线程通常没有用，在这些情况下会大放异彩，应该加以利用。附录D中引入的NUMA库使得寻找线程兄弟非常容易（参见附录中的示例）。如果库不可用，系统文件系统允许程序找到线程兄弟(参见表5.3中的thread_siblings列)。一旦这些信息可用，程序只需定义线程的安全性，然后以两种模式运行循环：正常操作和预取。预取的内存量应该取决于共享缓存的大小。在这个例子中，L2大小是相关的，程序可以使用 <code>sysconf(_SC_LEVEL2_CACHE_SIZE)</code>来查询大小。</p><p>是否必须限制辅助线程的进程取决于程序。一般来说，最好确保有一些同步，因为调度细节可能会导致显著的性能下降。</p><h3 id="直接cache存取">直接cache存取</h3><p>在现代操作系统中，高速缓存未命中的一个来源是对传入数据流量的处理。现代硬件，如网络接口卡（NIC）和磁盘控制器，能够在不涉及CPU的情况下将接收到的或读取的数据直接写入内存。这对我们今天拥有的设备的性能至关重要，但也会导致问题。假设来自网络的传入数据包：操作系统必须通过查看数据包的标头来决定如何处理它。NIC将数据包放入内存，然后通知处理器到达。处理器没有机会预取数据，因为它不知道数据何时到达，甚至可能不知道数据到底会存储在哪里。结果是读取标头时高速缓存未命中。</p><p>英特尔已经在他们的芯片组和CPU中添加了技术来缓解这个问题<a href="#refer-anchor-14">14</a>。这个想法是填充CPU的缓存，它将用数据包的数据通知传入的数据包。数据包的有效负载在这里并不重要，这些数据通常将由更高级别的函数处理，无论是在内核还是在用户级别。包报头用于决定必须处理数据包的方式，因此立即需要这些数据。</p><p>网络I/O硬件已经有DMA来写入数据包。这意味着它直接与可能集成在北桥中的内存控制器通信。内存控制器的另一面是通过FSB与处理器的接口(假设内存控制器没有集成到CPU本身)。</p><figure><img data-src="/posts/8bd607ed/figure-6.9a.webp" alt><figcaption>(a) DMA Initiated</figcaption></figure><p><img data-src="/posts/8bd607ed/figure-6.9b.webp" alt title="(b) DMA and DCA Executed">BeGji2TfvMGhVxGv</p><p>直接高速缓存访问(DCA)背后的想法是扩展NIC和内存控制器之间的协议。在图6.9中，第一张图显示了在具有北桥和南桥的普通机器中DMA传输的开始。NIC连接到（或是南桥的一部分）。它启动DMA访问，但提供了有关应推送到处理器缓存中的包报头的新信息。</p><p>传统的行为是，在第二步中，通过与内存的连接简单地完成DMA传输。对于使用DCA标志集的DMA传输，北桥还使用一个特殊的、新的DCA标志在FSB上发送数据。处理器总是窥探FSB，如果它识别出DCA标志，它会尝试将定向到处理器的数据加载到最低的缓存中。DCA标志实际上是一个提示；处理器可以自由地忽略它。DMA传输完成后，处理器会收到信号。</p><p>操作系统在处理数据包时，首先必须确定它是什么样的数据包。如果不忽略DCA提示，操作系统必须执行的负载来识别数据包最有可能到达缓存。将每个数据包节省的数百个周期乘以每秒可以处理的数万个数据包，这些节省加起来非常重要，尤其是在延迟方面。</p><p>少了 I/O 硬件（在这个例子中为 NIC）、晶片组与 CPU 的整合，这种最佳化是不可能的。因此，假如需要这个技术的话，确保明智地挑选平台是必要的。</p><h2 id="多线程优化">多线程优化</h2><p>谈到多线程，缓存使用在三个不同的方面很重要：</p><ul><li>并发</li><li>原子性</li><li>带宽</li></ul><p>这些方面也适用于多进程情况，但是，由于多个进程（大部分）是独立的，因此针对它们进行优化并不容易。可能的多进程优化是多线程场景中可用的优化的子集。因此，我们将在这里专门讨论后者。</p><p>在这种情况下，并发是指进程在一次运行多个线程时所经历的内存效应。线程的一个特性是它们都共享相同的地址空间，因此都可以访问相同的内存。在理想情况下，线程大部分时间使用的内存区域是不同的，在这种情况下，这些线程只是轻微耦合(例如，公共输入和/或输出)。如果多个线程使用相同的数据，则需要协调；这就是原子性发挥作用的时候。最后，根据机器架构，处理器可用的可用内存和处理器间总线带宽是有限的。我们将在以下部分分别处理这三个方面——当然，它们是紧密相连的。</p><h3 id="并发优化">并发优化</h3><p>实际上，在本节中，我们将讨论两个不同的问题，它们实际上需要相互矛盾的优化。多线程应用程序在其某些线程中使用公共数据。正常的缓存优化要求将数据保存在一起，以便应用程序的占用空间很小，从而最大化任何时候适合缓存的内存量。</p><blockquote><p>因为cache的最小单位为cache行。因此若是数据摆在一起，代表它们所占用的cache行数量较少，因此一次能cache的数据量就变多。</p></blockquote><p>但是，这种方法有一个问题：如果多个线程写入一个内存位置，缓存行必须在每个相应内核的L1d中处于“E”（独占）状态。这意味着发送大量RFO消息，在最坏的情况下，每次写入访问一条。因此，正常的写入将突然变得非常昂贵。如果使用相同的内存位置，则需要同步（可能通过使用原子操作，这将在下一节中处理）。但是，当所有线程都使用不同的内存位置并且应该是独立的时，问题也很明显。</p><p>图6.10显示了这种“错误共享”的结果。测试程序（如A.3节所示）创建了许多线程，这些线程除了增加内存位置（5亿次）之外什么也不做。测量的时间是从程序开始到程序在等待最后一个线程后完成。线程被固定在单个处理器上。机器有四个P4处理器。蓝色值表示分配给每个线程的内存分配在单独的高速缓存行上的运行。红色部分是线程位置移动到一个高速缓存行时发生的惩罚。</p><figure><img data-src="/posts/8bd607ed/figure-6.10.webp" alt><figcaption>图 6.10：并行cache行存取的间接成本</figcaption></figure><p>蓝色测量值（使用独立缓存行所需的时间）符合预期。该程序扩展到许多线程而不会受到惩罚。每个处理器都将其缓存行保存在自己的L1d中，并且没有带宽问题，因为不必读取太多代码或数据（事实上，它都被缓存了）。测量到的轻微增加实际上是系统噪声，可能还有一些预取效应（线程使用顺序缓存行）。</p><p>通过将每个线程使用一条高速缓存线所需的时间除以每条高速缓存线所需的时间来计算的测量开销分别为390%、734%和1,147%。这些大数字乍一看可能令人惊讶，但在考虑所需的高速缓存交互时，应该是显而易见的。高速缓存线在完成对高速缓存线的写入后立即从一个处理器的高速缓存中提取。<sup class="footnote-ref"><a href="#fn10" id="fnref10">[10]</a></sup>所有处理器，除了在任何给定时刻拥有高速缓存线的处理器之外，都被延迟并且不能做任何事情。每个额外的进程都只会导致更多的延迟。</p><figure><img data-src="/posts/8bd607ed/figure-6.11.webp" alt><figcaption>图 6.11：四个处理器核的间接成本</figcaption></figure><p>从这些测量结果可以清楚地看出，这种情况必须在程序中避免。考虑到巨大的代价，这个问题在许多情况下是显而易见的（分析至少会显示代码位置），但现代硬件存在一个陷阱。图6.11显示了在单个处理器四核机器（英特尔酷睿2 QX 6700）上运行代码时的等效测量结果。即使使用该处理器的两个独立L2，测试用例也没有显示任何可扩展性问题。多次使用相同的缓存行会有轻微的开销，但不会随着内核数量的增加而增加。如果使用多个处理器，我们当然会看到类似于图6.10中的结果。尽管多核处理器的使用越来越多，但许多机器将继续使用多个处理器，因此正确处理这种情况非常重要，这可能意味着在真实的SMP机器上测试代码。</p><p>这个问题有一个非常简单的“修复”：将每个变量放在自己的缓存行上。这就是与前面提到的优化发生冲突的地方，特别是，应用程序的占用空间会增加很多。这是不可接受的；因此有必要想出一个更智能的解决方案。</p><p>需要的是识别哪些变量一次只被一个线程使用，哪些变量永远只被一个线程使用，哪些变量有时是有争议的。对于这些场景中的每一个，不同的解决方案都是可能和有用的。区分变量的最基本标准是：它们是否曾经被写入以及这种情况发生的频率。</p><p>从不写入的变量和只初始化一次的变量基本上是常量。由于RFO消息只需要用于写入操作，因此常量可以在缓存（“S”状态）中共享。因此，这些变量不必被特殊处理；将它们组合在一起是好的。如果程序员用const正确标记变量，工具链将把变量从正常变量移至<code>.rodata</code>(只读数据)或<code>.data.rel.ro</code>(重新登录后只读)段。<sup class="footnote-ref"><a href="#fn11" id="fnref11">[11]</a></sup>不需要其他特殊操作。如果由于某种原因，变量不能用const正确标记，程序员可以通过将它们分配到一个特殊段来影响它们的位置。</p><p>当链接器构造最终的二进制文件时，它首先从所有输入文件中附加同名的部分；然后这些部分按照链接器脚本确定的顺序排列。这意味着，通过将所有基本上是常量但没有标记为常量的变量移动到一个特殊的部分中，程序员可以将所有这些变量组合在一起。它们之间不会有一个经常写入的变量。通过适当地对齐该部分中的第一个变量，可以保证不会发生错误共享。假设这个小例子：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="type">int</span> foo = <span class="number">1</span>;</span><br><span class="line"><span class="type">int</span> bar __attribute__((section(<span class="string">&quot;.data.ro&quot;</span>))) = <span class="number">2</span>;</span><br><span class="line"><span class="type">int</span> baz = <span class="number">3</span>;</span><br><span class="line"><span class="type">int</span> xyzzy __attribute__((section(<span class="string">&quot;.data.ro&quot;</span>))) = <span class="number">4</span>;</span><br></pre></td></tr></table></figure><p>如果被编译，这个输入文件定义了四个变量。有趣的是变量foo和baz，bar和xyzzy分别组合在一起。如果没有属性定义，编译器将按照源代码中定义的顺序将四个变量分配到，一个名为<code>.data</code> 的部分<sup class="footnote-ref"><a href="#fn12" id="fnref12">[12]</a></sup>。代码是这样的，变量bar和xyzzy被放置在一个名为.data.ro.部分名称.data.ro或多或少是任意的。.data的前缀。保证GNU链接器将把该部分与其他数据部分放在一起。</p><h1 id="参考">参考</h1><div id="refer-anchor-1"></div><ul><li>[1] <a target="_blank" rel="noopener" href="http://www.amd.com/us-en/assets/content_type/white_papers_and_tech_docs/40555.pdf">Performance Guidelines for AMD Athlon™ 64 and AMD Opteron™ ccNUMA Multiprocessor Systems. Advanced Micro Devices</a>, June 2006.</li></ul><div id="refer-anchor-2"></div><ul><li>[2] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/anderson97continuous.html">Jennifer M. Anderson, Lance M. Berc, Jeffrey Dean, Sanjay Ghemawat, Monika R. Henzinger, Shun-Tak A. Leung, Richard L. Sites, Mark T. Vandevoorde, Carl A. Waldspurger, and William E. Weihl. Continuous profiling: Where have all the cycles gone. In Proceedings of the 16th ACM Symposium of Operating Systems Principles, pages 1–14</a>, October 1997.</li></ul><div id="refer-anchor-3"></div><ul><li>[3] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/476689.html">Vinodh Cuppu, Bruce Jacob, Brian Davis, and Trevor Mudge. High-Performance DRAMs in Workstation Environments. IEEE Transactions on Computers, 50(11):1133–1153</a>, November 2001.</li></ul><div id="refer-anchor-4"></div><ul><li>[4] <a target="_blank" rel="noopener" href="https://ols2006.108.redhat.com/2007/Reprints/melo-Reprint.pdf">Arnaldo Carvalho de Melo. The 7 dwarves: debugging information beyond gdb. In Proceedings of the Linux Symposium</a>, 2007.</li></ul><div id="refer-anchor-5"></div><ul><li>[5] <a target="_blank" rel="noopener" href="http://research.sun.com/scalable/pubs/SPAA04.pdf">Simon Doherty, David L. Detlefs, Lindsay Grove, Christine H. Flood, Victor Luchangco, Paul A. Martin, Mark Moir, Nir Shavit, and Jr. Guy L. Steele. DCAS is not a Silver Bullet for Nonblocking Algorithm Design. In SPAA ’04: Proceedings of the Sixteenth Annual ACM Symposium on Parallelism in Algorithms and Architectures, pages 216–224, New York, NY, USA, 2004. ACM Press. ISBN 1-58113-840-7</a>.</li></ul><div id="refer-anchor-6"></div><ul><li>[6] <a target="_blank" rel="noopener" href="http://www.pcstats.com/articleview.cfm?articleID=1573">M. Dowler. Introduction to DDR-2: The DDR Memory Replacement</a>, May 2004.</li></ul><div id="refer-anchor-7"></div><ul><li>[7] <a target="_blank" rel="noopener" href="http://people.redhat.com/drepper/futex.pdf">Ulrich Drepper. Futexes Are Tricky</a>, December 2005</li></ul><div id="refer-anchor-8"></div><ul><li>[8] <a target="_blank" rel="noopener" href="http://people.redhat.com/drepper/tls.pdf">Ulrich Drepper. ELF Handling For Thread-Local Storage. Technical report, Red Hat, Inc</a>, 2003.</li></ul><div id="refer-anchor-9"></div><ul><li>[9] <a target="_blank" rel="noopener" href="http://people.redhat.com/drepper/nonselsec.pdf">Ulrich Drepper. Security Enhancements in Red Hat Enterprise Linux</a>, 2004.</li></ul><div id="refer-anchor-10"></div><ul><li>[10] <a target="_blank" rel="noopener" href="http://www.grame.fr/pub/fober-JIM2002.pdf">Dominique Fober, Yann Orlarey, and Stephane Letz. Lock-Free Techiniques for Concurrent Access to Shared Objects. In GMEM, editor, Actes des Journes d’Informatique Musicale JIM2002, Marseille, pages 143–150</a>,2002.</li></ul><div id="refer-anchor-11"></div><ul><li>[11] Joe Gebis and David Patterson. Embracing and Extending 20th-Century Instruction Set Architectures. Computer, 40(4):68–75, April 2007. 8.4</li></ul><div id="refer-anchor-12"></div><ul><li>[12] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/goldberg91what.html">David Goldberg. What Every Computer Scientist Should Know About Floating-Point Arithmetic. ACM Computing Surveys, 23(1):5–48</a>, March 1991.</li></ul><div id="refer-anchor-13"></div><ul><li>[13] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/herlihy93transactional.html">Maurice Herlihy and J. Eliot B. Moss. Transactional memory: Architectural support for lock-free data structures. In Proceedings of 20th International Symposium on Computer Architecture</a>, 1993.</li></ul><div id="refer-anchor-14"></div><ul><li>[14] <a target="_blank" rel="noopener" href="http://www.stanford.edu/group/comparch/papers/huggahalli05.pdf">Ram Huggahalli, Ravi Iyer, and Scott Tetrick. Direct Cache Access for High Bandwidth Network I/O</a>, 2005.</li></ul><div id="refer-anchor-15"></div><ul><li>[15] <a target="_blank" rel="noopener" href="http://www.intel.com/design/processor/manuals/248966.pdf">Intel R© 64 and IA-32 Architectures Optimization Reference Manual. Intel Corporation</a>, May 2007.</li></ul><div id="refer-anchor-16"></div><ul><li>[16] <a href="ftp://download.intel.com/technology/itj/2002/volume06issue01/art06_computeintensive/vol6iss1_art06">William Margo, Paul Petersen, and Sanjiv Shah. Hyper-Threading Technology: Impact on Compute-Intensive Workloads. Intel Technology Journal, 6(1)</a>, 2002.</li></ul><div id="refer-anchor-17"></div><ul><li>[17] <a target="_blank" rel="noopener" href="http://blogs.linux.ie/caolan/2007/04/24/controlling-symbol-ordering/">Caol ́an McNamara. Controlling symbol ordering</a>, April 2007.</li></ul><div id="refer-anchor-18"></div><ul><li>[18] Double Data Rate (DDR) SDRAM MT46V. Micron Technology, 2003. Rev. L 6/06 EN.</li></ul><div id="refer-anchor-19"></div><ul><li>[19] <a target="_blank" rel="noopener" href="http://arstechnica.com/paedia/r/ram_guide/ram_guide.part2-1.html">Jon “Hannibal” Stokes. Ars Technica RAM Guide, Part II: Asynchronous and Synchronous DRAM</a>, 2004.</li></ul><div id="refer-anchor-20"></div><ul><li>[20] <a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Static_Random_Access_Memory">Static random access memory - Wikipedia</a>, 2006.</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>这里我们忽略上溢（overflow）、下溢（underflow）、或是四舍五入（rounding）发生的可能算术影响 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>理论上在 1999 年修订版引入 C 语言的 <code>restrict</code> 关键字应该解决这个问题。不过编译器还是不理解。原因主要是存在著太多不正确的程序码，其会误导编译器、并导致它产生不正确的目的码（object code） <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>测试是在一台 32 bit机器上执行的，因此 <code>NPAD</code>=15 代表每个列表元素使用一个 64 byte cache行 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>气泡生动地描述在一个处理器的pipeline中执行的空洞，其会在执行必须等待资源的时候发生。关于更多细节，请读者参阅处理器设计的文献 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li><li id="fn5" class="footnote-item"><p>对某些处理器而言，cache行并非指令的最小区块（atomic block）。Intel Core 2 前端会将 16 byte区块发给解码器。它们会被适当的对齐，因此没有任何被发出的区块能横跨cache行边界。对齐到cache行的开头仍有优点，因为它最佳化预取的正面影响 <a href="#fnref5" class="footnote-backref">↩︎</a></p></li><li id="fn6" class="footnote-item"><p>对于指令解码，处理器往往会使用比cache行还小的单元，在 x86 与 x86-64 的情况中为 16 byte <a href="#fnref6" class="footnote-backref">↩︎</a></p></li><li id="fn7" class="footnote-item"><p>很快就会有更好的方法! <a href="#fnref7" class="footnote-backref">↩︎</a></p></li><li id="fn8" class="footnote-item"><p>或是 non-instruction。这是推荐的未定义操作码 <a href="#fnref8" class="footnote-backref">↩︎</a></p></li><li id="fn9" class="footnote-item"><p>r4 与 r8 相同指的是值会被覆写的情况。 <a href="#fnref9" class="footnote-backref">↩︎</a></p></li><li id="fn10" class="footnote-item"><p>因为所有线程写入的数据都在同个cache行内。因此刚写入的cache行立刻就会因为其它线程也要对相同的cache行进行写入，而变为「I（无效）」状态。 <a href="#fnref10" class="footnote-backref">↩︎</a></p></li><li id="fn11" class="footnote-item"><p>通过名称标识的段是包含ELF文件中的代码和数据的原子单元。 <a href="#fnref11" class="footnote-backref">↩︎</a></p></li><li id="fn12" class="footnote-item"><p>这并不受 ISO C 标准保证，但 gcc 是这么做的。 <a href="#fnref12" class="footnote-backref">↩︎</a></p></li></ol></section></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/b9e0656f/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/b9e0656f/" class="post-title-link" itemprop="url">What Every Programmer Should Know About Memory (1)</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-08-26 21:36:46" itemprop="dateCreated datePublished" datetime="2020-08-26T21:36:46+08:00">2020-08-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-11-08 11:19:15" itemprop="dateModified" datetime="2024-11-08T11:19:15+08:00">2024-11-08</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/Memory/" itemprop="url" rel="index"><span itemprop="name">Memory</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/b9e0656f/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/b9e0656f/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/b9e0656f/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>54k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>1:30</span></span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本文翻译自 <a target="_blank" rel="noopener" href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf#link=pdf">What Every Programmer Should Know About Memory</a>的第1,2,3章</p></blockquote><p>随着CPU内核变得更快、核数更多，目前或者说将来一段时间内大多数程序员的限制因素是内存访问。硬件设计人员想出了很多更复杂的内存处理和加速技术–例如CPU缓存。但是，如果没有程序员的帮助，这些技术没法以最佳方式生效。不幸的是，不论对计算机内存子系统或CPU缓存的结构，或是使用它们的花销，都没有被大多数程序员很好理解。本文解释了现代商品硬件上使用的内存子系统的结构，说明了为什么开发 CPU 缓存，它们如何工作，以及程序员应该做什么才能通过利用它们来实现最佳性能。</p><div class="post-button"><a class="btn" href="/posts/b9e0656f/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/92cd36ac/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/92cd36ac/" class="post-title-link" itemprop="url">What Every Programmer Should Know About Memory (2)</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-08-26 21:36:46" itemprop="dateCreated datePublished" datetime="2020-08-26T21:36:46+08:00">2020-08-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-11-08 11:15:13" itemprop="dateModified" datetime="2024-11-08T11:15:13+08:00">2024-11-08</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/Memory/" itemprop="url" rel="index"><span itemprop="name">Memory</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/92cd36ac/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/92cd36ac/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/92cd36ac/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>19k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>31 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本文翻译自 <a target="_blank" rel="noopener" href="https://people.freebsd.org/~lstewart/articles/cpumemory.pdf#link=pdf">What Every Programmer Should Know About Memory</a>的第4,5章</p></blockquote><h1 id="虚拟内存">虚拟内存</h1><p>处理器的虚拟内存子系统为每个进程实现了虚拟地址空间。这让每个进程认为它在系统中是独立的。虚拟内存的优点列表别的地方描述的非常详细，所以这里就不重复了。本节集中在虚拟内存的实际的实现细节，和相关的成本。</p><p>虚拟地址空间是由CPU的内存管理单元(MMU)实现的。OS必须填充页表数据结构，但大多数CPU自己做了剩下的工作。这事实上是一个相当复杂的机制；最好的理解它的方法是引入数据结构来描述虚拟地址空间。</p><p>由MMU进行地址翻译的输入地址是虚拟地址。通常对它的值很少有限制。 虚拟地址在32位系统中是32位的数值，在64位系统中是64位的数值。在一些系统，例如x86和x86-64，使用的地址实际上包含了另一个层次的间接寻址：这些结构使用分段，这些分段只是简单的给每个逻辑地址加上位移。我们可以忽略这一部分的地址产生，它不重要，不是程序员非常关心的内存处理性能方面的东西<sup class="footnote-ref"><a href="#fn1" id="fnref1">[1]</a></sup>。</p><h2 id="最简单的地址转换">最简单的地址转换</h2><p>有趣的地方在于由虚拟地址到物理地址的转换。MMU可以在逐页的基础上重新映射地址。就像地址缓存排列的时候，虚拟地址被分割为不同的部分。这些部分被用来做多个表的索引，而这些表是被用来创建最终物理地址用的。最简单的模型是只有一级表。</p><figure><img data-src="/posts/92cd36ac/figure-4.1.webp" alt="图 4.1：一层地址转译"><figcaption>图 4.1：一层地址转译</figcaption></figure><p>图 4.1 显示了虚拟地址的不同部分是如何使用的。高字节部分是用来选择一个页目录的条目；那个目录中的每个地址可以被OS分别设置。页目录条目决定了物理内存页的地址；页面中可以有不止一个条目指向同样的物理地址。完整的内存物理地址是由页目录获得的页地址和虚拟地址低字节部分合并起来决定的。页目录条目还包含一些附加的页面信息，如访问权限。</p><p>页目录的数据结构存储在内存中。OS必须分配连续的物理内存，并将这个地址范围的基地址存入一个特殊的寄存器。然后虚拟地址的适当的位被用来作为页目录的索引，这个页目录事实上是目录条目的列表。</p><p>作为一个具体的例子，这是 x86机器4MB分页设计。虚拟地址的位移部分是22位大小，足以定位一个4M页内的每一个字节。虚拟地址中剩下的10位指定页目录中1024个条目的一个。每个条目包括一个10位的4M页内的基地址，它与位移结合起来形成了一个完整的32位地址。</p><h2 id="多级页表">多级页表</h2><p>4MB的页不是规范，它们会浪费很多内存，因为OS需要执行的许多操作需要内存页的队列。对于4kB的页（32位机器的规范，甚至通常是64位机器的规范），虚拟地址的位移部分只有12位大小。这留下了20位作为页目录的指针。具有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mn>20</mn></msup></mrow><annotation encoding="application/x-tex">2^{20}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8141em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8141em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">20</span></span></span></span></span></span></span></span></span></span></span></span> 个条目的表是不实际的。即使每个条目只要4比特，这个表也要4MB大小。由于每个进程可能具有其唯一的页目录，因为这些页目录许多系统中物理内存被绑定起来。</p><p>解决办法是用多级页表。然后这些就能表示一个稀疏的大的页目录，目录中一些实际不用的区域不需要分配内存。因此这种表示更紧凑，使它可能为内存中的很多进程使用页表而并不太影响性能。.</p><p>今天最复杂的页表结构由四级构成。图4.2显示了这样一个实现的原理图。</p><figure><img data-src="/posts/92cd36ac/figure-4.2.webp" alt="图 4.2：四层地址转译"><figcaption>图 4.2：四层地址转译</figcaption></figure><p>在这个例子中，虚拟地址被至少分为五个部分。其中四个部分是不同的目录的索引。被引用的第4级目录使用CPU中一个特殊目的的寄存器。第4级到第2级目录的内容是对次低一级目录的引用。如果一个目录条目标识为空，显然就是不需要指向任何低一级的目录。这样页表树就能稀疏和紧凑。正如图4.1，第1级目录的条目是一部分物理地址，加上像访问权限的辅助数据。</p><p>为了决定相对于虚拟地址的物理地址，处理器先决定最高级目录的地址。这个地址一般保存在一个寄存器。然后CPU取出虚拟地址中相对于这个目录的索引部分，并用那个索引选择合适的条目。这个条目是下一级目录的地址，它由虚拟地址的下一部分索引。处理器继续直到它到达第1级目录，那里那个目录条目的值就是物理地址的高字节部分。物理地址在加上虚拟地址中的页面位移之后就完整了。这个过程称为页面树遍历。一些处理器（像x86和x86-64）在硬件中执行这个操作，其他的需要OS的协助。</p><p>系统中运行的每个进程可能需要自己的页表树。部分地共享树是可能的，但不如说这是个例外状况。因此如果页表树需要的内存尽可能小的话将对性能与可扩展性有利。理想的情况是将使用的内存紧靠着放在虚拟地址空间；但实际使用的物理地址不影响。一个小程序可能只需要第2，3，4级的一个目录和少许第1级目录就能应付过去。在一个采用4kB页面和每个目录512条目的x86-64机器上，这允许用4级目录对2MB定位（每一级一个）。1GB连续的内存可以被第2到第4级的一个目录和第1级的512个目录定位。</p><p>但是，假设所有内存可以被连续分配是太简单了。为了弹性起见，大多数情况下，一个进程的栈与堆的区域是被分配在地址空间中非常相反的两端。这样使得任一个区域可以根据需要尽可能的增长。这意味着最有可能需要两个第2级目录和相应的更多的低一级的目录。</p><p>但即使如此也不总是符合当前的实际状况。为了安全考量，一个可执行程序的多个部分（程序码、资料、堆积、堆叠、动态共享物件〔Dynamic Shared Object，DSO〕，又称共享函式库〔shared library〕）会被映射在随机化的地址上 <a href="#refer-anchor-9">9</a>。随机化扩大了不同部份的相对位置；这意味着，在一个进程里使用中的不同memory区域会广泛地散布在虚拟定址空间中。通过对随机的地址位数采用一些限定，范围可以被限制，但在大多情况下会让一个进程无法以仅仅一或两个第二与第三层目录来执行。</p><p>如果性能真的远比安全重要，随机化可以被关闭。操作系统通常至少会在虚拟memory中连续地载入所有的 DSO。</p><h2 id="优化页表访问">优化页表访问</h2><p>页表的所有数据结构都保存在主存中；在那里OS建造和更新这些表。当一个进程创建或者一个页表变化，CPU将被通知。页表被用来解决每个虚拟地址到物理地址的转换，用上面描述的页表遍历方式。更多有关于此：至少每一级有一个目录被用于处理虚拟地址的过程。这需要至多四次内存访问（对一个运行中的进程的单次访问来说），这很慢。。将这些目录表的项目视为普通的资料、并在 L1d、L2、等等cache它们是办得到的，但这可能还是太慢了。</p><p>从虚拟内存的早期阶段开始，CPU的设计者采用了一种不同的优化。简单的计算显示，只有将目录表条目保存在L1d和更高级的缓存，才会导致可怕的性能问题。每个绝对地址的计算，都需要相对于页表深度的大量的L1d访问。这些访问不能并行，因为它们依赖于前面查询的结果。在一个四级页表的机器上，这种单线性将至少需要12次循环。再加上L1d的非命中的可能性，结果是指令流水线无法隐藏任何东西。额外的L1d访问也消耗了珍贵的缓存带宽。</p><p>所以，不只是将目录表的项目cache起来，而是连实体分页地址的完整计算结果也会被cache。因为同样的原因，代码和数据缓存也工作起来，这样的地址计算结果的缓存是高效的。由于虚拟地址的页面位移部分在物理页地址的计算中不起任何作用，只有虚拟地址的剩余部分被用作缓存的标签。根据页面大小这意味着成百上千的指令或数据对象共享同一个标签，因此也共享同一个物理地址前缀。</p><p>保存计算数值的缓存叫做旁路转换缓存(Translation Look-Aside Buffer，TLB)。因为它必须非常的快，通常这是一个小的缓存。现代CPU像其它缓存一样，提供了多级TLB缓存；越高级的缓存越大越慢。小容量的L1级TLB通常被用来做全关联式缓存，采用LRU回收策略。近来，这种cache的大小已经持续成长，并且渐渐被转变为集合关联式。因此，当一个新的项目必须被加入时，被逐出并取代的项目可能不是最旧的一个。</p><p>正如上面提到的，用来访问TLB的标签是虚拟地址的一个部分。如果标签在缓存中有匹配，最终的物理地址将被计算出来，通过将来自虚拟地址的页面位移地址加到缓存值的方式。这是一个非常快的过程；也必须这样，因为每条使用绝对地址的指令都需要物理地址，还有在一些情况下，因为使用物理地址作为关键字的L2查找。如果TLB查询未命中，处理器就必须执行一次页表遍历；这可能代价非常大。</p><p>通过软件或硬件预取代码或数据，会在地址位于另一页面时，暗中预取TLB的条目。硬件预取不可能允许这样，因为硬件会初始化非法的页面表遍历。因此程序员不能依赖硬件预取机制来预取TLB条目。它必须使用预取指令明确的完成。就像数据和指令缓存，TLB可以表现为多个等级。正如数据缓存，TLB通常表现为两种形式：指令TLB(ITLB)和数据TLB(DTLB)。高级的TLB像L2TLB通常是统一的，就像其他的缓存情形一样。</p><h3 id="使用TLB的注意事项">使用TLB的注意事项</h3><p>TLB是以处理器为核心的全局资源。所有运行于处理器的线程与进程使用同一个TLB。由于虚拟到物理地址的转换依赖于设置的是哪一种页表树，如果页表变化了，CPU不能盲目的重复使用缓存的条目。每个进程有一个不同的页表树（不算在同一个进程中的线程），内核与内存管理器VMM(管理程序)也一样，如果存在的话。也有可能一个进程的地址空间布局发生变化。有两种解决这个问题的办法：</p><ul><li>当页表树变化时TLB刷新。</li><li>扩充 TLB 项目的标签，以额外且唯一地识别它们所指涉到的分页表树。</li></ul><p>第一种情况，只要执行一个上下文切换TLB就被刷新。因为大多数OS中，从一个线程/进程到另一个的切换需要执行一些核心代码，TLB刷新被限制在进入或离开核心地址空间时。在虚拟化的系统上，当系统核心必须呼叫 VMM、并在返回的途中时，这也会发生。如果内核和/或内存管理器没有使用虚拟地址，或者当进程或内核调用系统/内存管理器时，能重复使用同一个虚拟地址（即，定址空间被重叠了），TLB必须被刷新。TLB 必须在离开系统核心或 VMM 后，处理器恢复一个不同的进程或系统核心的执行时被刷新。</p><p>刷新TLB高效但昂贵。例如，当执行一个系统调用，触及的内核代码可能仅限于几千条指令，或许少许新页面（或一个大的页面，像某些结构的Linux的就是这样）。这个工作将替换触及页面的所有TLB条目。对Intel带128ITLB和256DTLB条目的Core2架构，完全的刷新意味着多于100和200条目（分别的）将被不必要的刷新。当系统调用返回同一个进程，所有那些被刷新的TLB条目可能被再次用到，但它们没有了。内核或内存管理器常用的代码也一样。所有那些被刷新的 TLB 项目都能够被再次用到，但它们将会被丢掉。对于在系统核心或 VMM 中经常用到的程序码亦是如此。即使内核与内存管理器的页表通常不会改变。因此理论上说，TLB条目可以被保持一个很长时间。但在每次进入系统核心时，TLB 也必须从零开始填入。这也解释了为何现今处理器中的 TLB cache并没有更大的原因：程序的执行时间非常可能不会长到足以填入这所有的项目。</p><p>这个事实当然不会逃出 CPU 架构师的掌心。最佳化cache刷新的一个可能性是，单独令 TLB 项目失效。例如，如果内核代码与数据落于一个特定的地址范围，只有落入这个地址范围的页面必须被清除出TLB。这只需要比较标签，因此不是很昂贵。如果地址空间的一部分发生了变化，例如，通过调用munmap，这种方法也很有用。</p><p>更好的解决方法是为TLB访问扩展标签。如果除了虚拟地址的一部分之外，一个唯一的对应每个页表树的标识（如一个进程的地址空间）被添加，TLB将根本不需要完全刷新。内核，内存管理程序，和独立的进程都可以有唯一的标识。这种场景唯一的问题在于，TLB标签可以获得的位数异常有限，但是地址空间的位数却不是。这意味着一些标识的再利用是有必要的。这种情况发生时TLB必须部分刷新（如果可能的话）。所有带有再利用标识的条目必须被刷新，但是希望这是一个非常小的集合。</p><p>当多个进程运行在系统中时，这种扩展的TLB标签具有一般优势。如果每个可运行进程对内存的使用（因此TLB条目的使用）做限制，进程最近使用的TLB条目,当其再次列入计划时，有很大机会仍然在TLB。但还有两个额外的优势：</p><ul><li>特殊的地址空间，像内核和内存管理器使用的那些，经常仅仅进入一小段时间；之后控制经常返回初始化此次调用的地址空间。没有标签，就有两次TLB刷新操作。有标签，调用地址空间缓存的转换地址将被保存，而且由于内核与内存管理器地址空间根本不会经常改变TLB条目，系统调用之前的地址转换等等可以仍然使用。</li><li>当同一个进程的两个线程之间切换时，TLB刷新根本就不需要。虽然没有扩展TLB标签时，进入内核的条目会破坏第一个线程的TLB的条目。</li></ul><p>有些处理器在一些时候实现了这些扩展标签。AMD给帕西菲卡（Pacifica）虚拟化扩展引入了一个1位的扩展标签。在虚拟化的上下文中，这个1位的地址空间ID（ASID）被用来从客户域区别出内存管理程序的地址空间。这使得OS能够避免在每次进入内存管理程序的时候（例如为了处理一个页面错误）刷新客户的TLB条目，或者当控制回到客户时刷新内存管理程序的TLB条目。这个架构未来会允许使用更多的位。其它主流处理器很可能会随之适应并支持这个功能。</p><h3 id="影响TLB性能">影响TLB性能</h3><p>有一些因素会影响TLB性能。第一个是页面的大小。显然页面越大，装进去的指令或数据对象就越多。所以较大的页面大小减少了所需的地址转换总次数，即需要更少的TLB缓存条目。大多数架构允许使用多个不同的页面尺寸；一些尺寸可以并存使用。例如，x86/x86-64处理器有一个普通的4kB的页面尺寸，但它们也可以分别用4MB和2MB页面。IA-64 和 PowerPC允许如64kB的尺寸作为基本的页面尺寸。</p><p>然而，大页面尺寸的使用也随之带来了一些问题。用作大页面的内存范围必须是在物理内存中连续的。如果物理内存管理的单元大小升至虚拟内存页面的大小，浪费的内存数量将会增长。各种内存操作（如加载可执行文件）需要页面边界对齐。这意味着平均每次映射浪费了物理内存中页面大小的一半。这种浪费很容易累加；因此它给物理内存分配的合理单元大小划定了一个上限。</p><p>在x86-64结构中增加单元大小到2MB来适应大页面当然是不实际的。这是一个太大的尺寸。但这转而意味着每个大页面必须由许多小一些的页面组成。这些小页面必须在物理内存中连续。以4kB单元页面大小分配2MB连续的物理内存具有挑战性。它需要找到有512个连续页面的空闲区域。在系统运行一段时间并且物理内存开始碎片化以后，这可能极为困难（或者不可能）</p><p>因此在 Linux 上，有必要在系统启动的时候使用特殊的 hugetlbfs 档案系统来分配这些大分页。一个固定数量的实体分页会被保留来专门作为大虚拟分页来使用。这绑住了可能不会一直用到的资源。这也是个有限的池（pool）；增加它通常代表著重新启动系统。尽管如此，在效能贵重、资源充足、且麻烦的设置不是个大阻碍的情况下，庞大的分页便为大势所趋。数据库服务器就是个例子。</p><figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">$ eu-readelf -l /bin/ls</span><br><span class="line">Program Headers:</span><br><span class="line">  Type   Offset   VirtAddr           PhysAddr           FileSiz  MemSiz   Flg Align</span><br><span class="line">...</span><br><span class="line">  LOAD   0x000000 0x0000000000400000 0x0000000000400000 0x0132ac 0x0132ac R E 0x200000</span><br><span class="line">  LOAD   0x0132b0 0x00000000006132b0 0x00000000006132b0 0x001a71 0x001a71 RW  0x200000</span><br><span class="line">...</span><br></pre></td></tr></table></figure><figcaption>图 4.3：ELF 程序标头指示了对齐需求</figcaption></figure><p>提高最小的虚拟分页大小（对比于可选的大分页）也有它的问题。memory映射操作（例如，载入应用程序）必须遵循这些分页大小。不可能有更小的映射。一个可执行程序不同部分的位置 –– 对大多架构而言 –– 有个固定的关系。若是分页大小增加到超过在可执行程序或者 DSO 创建时所考虑的大小时，就无法执行载入操作。将这个限制记在心上是很重要的。图 4.3 显示了能够如何决定一个 ELF 二进位资料（binary）的对齐需求的。它被编码在 ELF 的程序标头（header）。在这个例子中，一个 x86-64 的二进位资料，值为 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>20000</mn><msub><mn>0</mn><mn>16</mn></msub><mo>=</mo><mn>2</mn><mo separator="true">,</mo><mn>097</mn><mo separator="true">,</mo><mn>152</mn><mo>=</mo><mtext>2MB</mtext></mrow><annotation encoding="application/x-tex">200000_{16} = 2,097,152 = \text{2MB}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.7944em;vertical-align:-.15em"></span><span class="mord">20000</span><span class="mord"><span class="mord">0</span><span class="msupsub"><span class="vlist-t vlist-t2"><span class="vlist-r"><span class="vlist" style="height:.3011em"><span style="top:-2.55em;margin-left:0;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mtight">16</span></span></span></span></span><span class="vlist-s">​</span></span><span class="vlist-r"><span class="vlist" style="height:.15em"><span></span></span></span></span></span></span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.8389em;vertical-align:-.1944em"></span><span class="mord">2</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">097</span><span class="mpunct">,</span><span class="mspace" style="margin-right:.1667em"></span><span class="mord">152</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord text"><span class="mord">2MB</span></span></span></span></span> ，与处理器所支援的最大分页大小相符。</p><p>使用较大的分页大小有个次要的影响：分页表树的层级数量会被减低。由于对应到分页偏移量的虚拟地址部分增加了，就没有剩下那么多需要透过分页目录处理的bit了。这表示，在一次 TLB 错失的情况下，必须完成的工作总量减少了。</p><p>除了使用大分页尺寸外，也可能借由将同时用到的资料搬移到较少的分页上，以减少所需的 TLB 项目数量。这类似于我们先前讨论的针对cache使用的一些最佳化。 只有现在对齐需求是巨大的。 考虑到 TLB 项目的数量非常少，这会是个重要的最佳化。</p><h2 id="虚拟化的影响">虚拟化的影响</h2><p>操作系统映像的虚拟化将变得越来越普遍；这意味着在图片中添加了另一层内存处理。进程（基本监狱）或操作系统容器的虚拟化不属于这一类，因为只涉及一个操作系统。Xen或KVM等技术——无论有没有处理器的帮助——都可以执行独立的操作系统映像。在这种情况下，只有一个软件可以直接控制对物理内存的访问。</p><figure><img data-src="/posts/92cd36ac/figure-4.4.webp" alt="图 4.4：Xen 虚拟化模型"><figcaption>图 4.4：Xen 虚拟化模型</figcaption></figure><p>在Xen的例子中（参见图4.4），Xen VMM就是那个软件。不过，VMM本身并没有实现许多其他硬件控制。与其他早期系统（以及Xen VMM的第一次重新租用）上的VM不同，内存和处理器之外的硬件由享有特权的Dom0域控制。现在，这基本上与没有特权的DomU内核一样，就内存处理方面而言，它们没有什么不同。这里重要的是，VMM将物理内存分配给Dom0和DomU内核，然后它们自己实现通常的内存处理，就好像它们在处理器上直接运行一样。</p><p>为了实现完成虚拟化所需的各个域之间的分隔，Dom0和DomU内核中的内存处理不具有无限制的物理内存访问权限。VMM不是通过分发独立的物理页并让客户OS处理地址的方式来分发内存；这不能提供对错误或欺诈客户域的防范。替代的，VMM为每一个客户域创建它自己的页表树，并且用这些数据结构分发内存。好处是对页表树管理信息的访问能得到控制。如果代码没有合适的特权，它不能做任何事。 在虚拟化的Xen支持中，这种访问控制已被开发，不管使用的是参数的或硬件的（又名全）虚拟化。客户域以意图上与参数的和硬件的虚拟化极为相似的方法，给每个进程创建它们的页表树。每当客户OS修改了VMM调用的页表，VMM就会用客户域中更新的信息去更新自己的影子页表。这些是实际由硬件使用的页表。显然这个过程非常昂贵：每次对页表树的修改都需要VMM的一次调用。而没有虚拟化时内存映射的改变也不便宜，它们现在变得甚至更昂贵。 考虑到从客户OS的变化到VMM以及返回，其本身已经相当昂贵，额外的代价可能真的很大。这就是为什么处理器开始具有避免创建影子页表的额外功能。这样很好不仅是因为速度的问题，而且它减少了VMM消耗的内存。Intel有扩展页表(EPTs)，AMD称之为嵌套页表(NPTs)。基本上两种技术都具有客户OS的页表，来产生虚拟的物理地址。然后通过每个域一个EPT/NPT树的方式，这些地址会被进一步转换为真实的物理地址。这使得可以用几乎非虚拟化情境的速度进行内存处理，因为大多数用来内存处理的VMM条目被移走了。它也减少了VMM使用的内存，因为现在一个域（相对于进程）只有一个页表树需要维护。 额外的地址转换步骤的结果也存储于TLB。那意味着TLB不存储虚拟物理地址，而替代以完整的查询结果。已经解释过AMD的帕西菲卡扩展为了避免TLB刷新而给每个条目引入ASID。ASID的位数在最初版本的处理器扩展中是一位；这正好足够区分VMM和客户OS。Intel有服务同一个目的的虚拟处理器ID(VPIDs)，它们只有更多位。但对每个客户域VPID是固定的，因此它不能标记单独的进程，也不能避免TLB在那个级别刷新。</p><p>对虚拟OS，每个地址空间的修改需要的工作量是一个问题。但是还有另一个内在的基于VMM虚拟化的问题：没有什么办法处理两层的内存。但内存处理很难（特别是考虑到像NUMA一样的复杂性，见第5部分）。Xen方法使用一个单独的VMM，这使最佳的（或最好的）处理变得困难，因为所有内存管理实现的复杂性，包括像发现内存范围之类“琐碎的”事情，必须被复制于VMM。OS有完全成熟的与最佳的实现；人们确实想避免复制它们。</p><figure><img data-src="/posts/92cd36ac/figure-4.5.webp" alt="图 4.5：KVM 虚拟化模型"><figcaption>图 4.5：KVM 虚拟化模型</figcaption></figure><p>这就是为什么对VMM/Dom0模型的分析是这么有吸引力的一个选择。图4.5显示了KVM的Linux内核扩展如何尝试解决这个问题的。并没有直接运行在硬件之上且管理所有客户的单独的VMM，替代的，一个普通的Linux内核接管了这个功能。这意味着Linux内核中完整且复杂的内存管理功能，被用来管理系统的内存。客户域运行于普通的用户级进程，创建者称其为“客户模式”。虚拟化的功能，参数的或全虚拟化的，被另一个用户级进程KVM VMM控制。这也就是另一个进程用特别的内核实现的KVM设备，去恰巧控制一个客户域。</p><p>这个模型相较Xen独立的VMM模型好处在于，即使客户OS使用时，仍然有两个内存处理程序在工作，只需要在Linux内核里有一个实现。不需要像Xen VMM那样从另一段代码复制同样的功能。这带来更少的工作，更少的bug，或许还有更少的两个内存处理程序接触产生的摩擦，因为一个Linux客户的内存处理程序与运行于裸硬件之上的Linux内核的外部内存处理程序，做出了相同的假设。</p><p>总的来说，程序员必须清醒认识到，采用虚拟化时，内存操作的代价比没有虚拟化要高很多。任何减少这个工作的优化，将在虚拟化环境付出更多。随着时间的过去，处理器的设计者将通过像EPT和NPT技术越来越减少这个差距，但它永远都不会完全消失。</p><h1 id="NUMA-支持">NUMA 支持</h1><p>在第二部分中，我们看到在某些机器上，访问物理内存特定区域的成本取决于访问的来源。这种类型的硬件需要操作系统和应用程序特别注意。我们将从 NUMA 硬件的一些细节开始，然后再介绍 Linux 内核为 NUMA 提供的一些支持。</p><h2 id="NUMA-硬件">NUMA 硬件</h2><p>非均匀内存体系结构越来越普遍。在最简单的 NUMA 形式中，处理器可以具有本地内存（参见图2.3），其访问成本比其他处理器本地内存要便宜。这种类型的 NUMA 系统的成本差异并不高，即 NUMA 因子很低。</p><p>NUMA 还特别用于大型机器。我们已经描述了许多处理器访问同一内存所带来的问题。对于商用硬件，所有处理器都将共享同一个北桥（暂不考虑 AMD Opteron NUMA 节点，它们有自己的问题）。这使得北桥成为一个严重的瓶颈，因为所有内存流量都通过它进行路由。当然，大型机器可以使用自定义硬件代替北桥，但是，除非使用的内存芯片具有多个端口，即它们可以从多个总线中使用，否则仍然存在瓶颈。多端口 RAM 很复杂，成本很高，因此几乎不会使用。</p><p>复杂度的下一个增加是 AMD 使用的模型，其中一种互连机制（在 AMD 的情况下是 Hypertransport，这是他们从 Digital 获得许可的技术）为未直接连接到 RAM 的处理器提供访问。这种方式可以形成的结构的大小受到限制，除非想任意增加直径（即任意两个节点之间的最大距离）。</p><figure><img data-src="/posts/92cd36ac/figure-5.1.webp" alt="图 5.1：超立方体"><figcaption>图 5.1：超立方体</figcaption></figure><p>一种连接节点的高效拓扑（topology）为超立方体（hypercube），其将节点的数量限制在 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>C</mi></msup></mrow><annotation encoding="application/x-tex">2^{C}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.8413em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.8413em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight" style="margin-right:.07153em">C</span></span></span></span></span></span></span></span></span></span></span></span>，其中 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span> 为每个节点拥有的交互连接介面的数量。以所有有著 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mn>2</mn><mi>n</mi></msup></mrow><annotation encoding="application/x-tex">2^{n}</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6644em"></span><span class="mord"><span class="mord">2</span><span class="msupsub"><span class="vlist-t"><span class="vlist-r"><span class="vlist" style="height:.6644em"><span style="top:-3.063em;margin-right:.05em"><span class="pstrut" style="height:2.7em"></span><span class="sizing reset-size6 size3 mtight"><span class="mord mtight"><span class="mord mathnormal mtight">n</span></span></span></span></span></span></span></span></span></span></span></span> 个 CPU 与 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi></mrow><annotation encoding="application/x-tex">n</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.4306em"></span><span class="mord mathnormal">n</span></span></span></span> 条交互连接的系统而言，超立方体拥有最小的直径。图 5.1 显示了前三种超立方体。每个超立方体拥有绝对最小（the absolute minimum）的直径 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span></span></span></span>。AMD 第一世代的 Opteron 处理器，每个处理器拥有三条超传输连结。至少有一个处理器必须有个附属在一条连结上的南桥，代表 –– 目前而言 –– 一个 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">C = 2</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">2</span></span></span></span> 的超立方体能够直接且有效率地实作。下个世代将在某个时间点拥有四条连结，届时将可能有 <span class="katex"><span class="katex-mathml"><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mn>3</mn></mrow><annotation encoding="application/x-tex">C = 3</annotation></semantics></math></span><span class="katex-html" aria-hidden="true"><span class="base"><span class="strut" style="height:.6833em"></span><span class="mord mathnormal" style="margin-right:.07153em">C</span><span class="mspace" style="margin-right:.2778em"></span><span class="mrel">=</span><span class="mspace" style="margin-right:.2778em"></span></span><span class="base"><span class="strut" style="height:.6444em"></span><span class="mord">3</span></span></span></span> 的超立方体。</p><p>但这并不意味着不支持更大的处理器积累。一些公司已经开发了交叉开关，允许使用更大的处理器集合（例如Newisys的Horus）。但是这些交叉开关会增加NUMA因素，并且在一定数量的处理器上不再有效。</p><p>下一步是连接CPU组并为它们实现共享内存。所有这样的系统都需要专用硬件，绝不是商品系统。这样的设计存在多个复杂度级别。一个仍然非常接近商品机的系统是IBM x445和类似的机器。它们可以作为普通的4U，8路机器购买，带有x86和x86-64处理器。然后可以将两个（在某些时候最多四个）这样的机器连接起来，以共享内存的方式作为一个单一的机器。所使用的互连引入了一个显著的NUMA因素，这是操作系统以及应用程序必须考虑的。</p><p>在另一端的系统中，像SGI的Altix就是专门设计用于互连。SGI的NUMAlink互连结构非常快且延迟低，这些都是高性能计算（HPC）的要求，特别是当使用消息传递接口（MPI）时。缺点当然是这种复杂性和专业化非常昂贵。它们可以实现相对较低的NUMA因素，但由于这些机器可以拥有数千个CPU并且互连的容量有限，NUMA因素实际上是动态的，取决于工作负载而可能达到不可接受的水平。</p><p>更常见的解决方案是使用高速网络连接商品机集群。但这些不是NUMA机器；它们不实现共享地址空间，因此不属于本文讨论的任何类别。</p><h2 id="操作系统对-NUMA-的支援">操作系统对 NUMA 的支援</h2><p>为了支持NUMA机器，操作系统必须考虑内存的分布性质。例如，如果在给定的处理器上运行一个进程，则分配给该进程地址空间的物理RAM应来自本地内存。否则，每个指令都必须访问远程内存以获取代码和数据。在NUMA机器中存在需要考虑的特殊情况。DSO的文本段（text segment）在一台机器的实体 RAM 中通常正好出现一次。但是，如果DSO由所有CPU上的进程和线程使用（例如基本运行库如libc），这意味着除了少数处理器外，其他处理器都必须具有远程访问。理想情况下，操作系统应该将这些DSO“镜像”到每个处理器的物理RAM中，并使用本地副本。这是一种优化而不是要求，并且通常难以实现。它可能不被支持或仅以有限的方式支持。</p><p>为避免情况恶化，操作系统不应将进程或线程从一个节点迁移至另一个节点。在普通的多处理器机器上，操作系统已经尝试避免迁移进程，因为从一个处理器迁移到另一个处理器意味着缓存内容会丢失。如果负载分配需要将进程或线程从处理器迁移，操作系统通常可以选择具有足够剩余容量的任意新处理器。在NUMA环境中，选择新处理器的范围略有限制。新选择的处理器不应该比旧处理器更高地访问进程正在使用的内存，这限制了可选目标列表。如果没有可用满足该标准的空闲处理器，则操作系统别无选择，只能迁移到访问内存更昂贵的处理器。</p><p>在这种情况下，有两种可能的方法。首先，可以希望情况是暂时的，并且进程可以迁回到更合适的处理器。或者，操作系统也可以将进程的内存迁移到更靠近新使用的处理器的物理页面。这是一项非常昂贵的操作。可能需要复制大量的内存，尽管不一定在一步完成。在此过程中，进程至少要被暂停，以便正确迁移旧页面的修改。还有一系列其他要求，以使页面迁移高效快速。简而言之，除非确实需要，否则操作系统应该避免进行此操作。</p><p>通常情况下，Linux内核不会假设所有在NUMA机器上运行的进程都使用相同数量的内存，因此在进程分布在不同处理器上的情况下，内存使用情况也是不平衡的。实际上，除非在HPC领域等特定应用中，运行在机器上的应用程序所使用的内存将会非常不平衡。一些应用程序会使用大量的内存，而其他应用程序则几乎不使用内存。如果总是将内存分配到发出请求的处理器上，这将最终导致问题。当运行大型进程的节点内存不足时，系统将出现问题。</p><p>为了应对这些严重的问题，默认情况下不会仅在本地节点上分配内存。为了利用系统的所有内存， 默认策略是将内存分割成多个条带。这可以保证所有系统内存的使用是均衡的。副作用是可以在处理器之间自由迁移进程，因为平均而言，所有使用的内存的访问成本都不会改变。对于小的NUMA因子，分条是可以接受但仍不是最优的（请参见第5.4节中的数据）。</p><p>这是一种负优化，有助于系统避免严重问题并使其在正常操作下更可预测。但是，它确实降低了整个系统的性能，在某些情况下甚至会显著降低。这就是为什么Linux允许每个进程选择内存分配规则。进程可以为自身及其子进程选择不同的策略。我们将在第6节中介绍可以用于此的接口。</p><h2 id="消息发布">消息发布</h2><p>内核通过 sys 伪文件系统（sysfs）发布有关处理器缓存的信息，其路径如下：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sys/devices/system/cpu/cpu*/cache</span><br></pre></td></tr></table></figure><p>在 6.2.1 节，我们会看到能用来查询不同cache大小的介面。这里重要的是cache的拓朴。上面的目录包含了列出 CPU 拥有的不同cache资讯的子目录（叫做 <code>index*</code>）。档案 <code>type</code>、<code>level</code>、与 <code>shared_cpu_map</code> 是在这些目录中与拓朴有关的重要档案。一个 Intel Core 2 QX6700 的资讯看起来就如表 5.1。</p><figure><table><tr><th colspan="2"></th><th><code>type</code></th><th><code>level</code></th><th><code>shared_cpu_map</code></th></tr><tr><td rowspan="3"><code>cpu0</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000001</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000001</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000003</td></tr><tr><td rowspan="3"><code>cpu1</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000002</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000002</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000003</td></tr><tr><td rowspan="3"><code>cpu2</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000004</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000004</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>0000000c</td></tr><tr><td rowspan="3"><code>cpu3</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000008</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000008</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>0000000c</td></tr></table><figcaption>表 5.1：Core 2 CPU cache的 <code>sysfs</code> 资讯</figcaption></figure><p>这份资料的意义如下：</p><ul><li>每颗处理器核<sup class="footnote-ref"><a href="#fn2" id="fnref2">[2]</a></sup>拥有三个cache：L1i、L1d、L2。</li><li>L1d 与 L1i cache没有被任何其它的处理器核所共享 –– 每颗处理器核有它自己的一组cache。这是由 <code>shared_cpu_map</code> 中的bit图（bitmap）只有一个被设置的bit所暗示的。</li><li><code>cpu0</code> 与 <code>cpu1</code> 的 L2 cache是共享的，正如 <code>cpu2</code> 与 <code>cpu3</code> 上的 L2 一样。</li></ul><p>若是 CPU 有更多cache阶层，也会有更多的 <code>index*</code> 目录。</p><figure><table><tr><th colspan="2"></th><th><code>type</code></th><th><code>level</code></th><th><code>shared_cpu_map</code></th></tr><tr><td rowspan="3"><code>cpu0</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000001</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000001</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000001</td></tr><tr><td rowspan="3"><code>cpu1</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000002</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000002</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000002</td></tr><tr><td rowspan="3"><code>cpu2</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000004</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000004</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000004</td></tr><tr><td rowspan="3"><code>cpu3</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000008</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000008</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000008</td></tr><tr><td rowspan="3"><code>cpu4</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000010</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000010</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000010</td></tr><tr><td rowspan="3"><code>cpu5</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000020</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000020</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000020</td></tr><tr><td rowspan="3"><code>cpu6</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000040</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000040</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000040</td></tr><tr><td rowspan="3"><code>cpu7</code></td><td><code>index0</code></td><td>Data</td><td>1</td><td>00000080</td></tr><tr><td><code>index1</code></td><td>Instruction</td><td>1</td><td>00000080</td></tr><tr><td><code>index2</code></td><td>Unified</td><td>2</td><td>00000080</td></tr></table><figcaption>表 5.2：Opteron CPU cache的 <code>sysfs</code> 资讯</figcaption></figure><p>对于一个四槽、双核的 Opteron 机器，cache资讯看起来如表 5.2。可以看出这些处理器也有三种cache：L1i、L1d、L2。没有处理器核共享任何阶层的cache。这个系统有趣的部分在于处理器拓朴。少了这个额外信息，就无法理解cache资料。<code>sys</code> 档案系统将这个信息放在下面这个文件中。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sys/devices/system/cpu/cpu*/topology</span><br></pre></td></tr></table></figure><p>表格5.3展示了SMP Opteron机器在这个层次结构中的有趣文件。</p><figure><table><tr><th></th><th><code>physical_<br>package_id</code></th><th><code>core_id</code></th><th><code>core_<br>siblings</code></th><th><code>thread_<br>siblings</code></th></tr><tr><td><code>cpu0</code></td><td rowspan="2">0</td><td>0</td><td>00000003</td><td>00000001</td></tr><tr><td><code>cpu1</code></td><td>1</td><td>00000003</td><td>00000002</td></tr><tr><td><code>cpu2</code></td><td rowspan="2">1</td><td>0</td><td>0000000c</td><td>00000004</td></tr><tr><td><code>cpu3</code></td><td>1</td><td>0000000c</td><td>00000008</td></tr><tr><td><code>cpu4</code></td><td rowspan="2">2</td><td>0</td><td>00000030</td><td>00000010</td></tr><tr><td><code>cpu5</code></td><td>1</td><td>00000030</td><td>00000020</td></tr><tr><td><code>cpu6</code></td><td rowspan="2">3</td><td>0</td><td>000000c0</td><td>00000040</td></tr><tr><td><code>cpu7</code></td><td>1</td><td>000000c0</td><td>00000080</td></tr></table><figcaption>表 5.3：Opteron CPU 拓朴的 <code>sysfs</code> 资讯</figcaption></figure><p>将表 5.2 与 5.3 摆在一起，我们能够发现</p><ul><li>没有 CPU 拥有 HT （<code>thethread_siblings</code> bit图有一个bit被设置）、</li><li>这个系统实际上共有四个处理器（<code>physical_package_id</code> 0 到 3）、</li><li>每个处理器有两颗核、以及没有处理器核共享任何cache。</li></ul><p>这正好与较早期的 Opteron 一致。</p><p>迄今为止提供的数据完全缺乏有关此机器NUMA性质的信息。任何SMP Opteron机器都是NUMA机器。对于这些数据，我们必须查看“sys”文件系统的另一部分，该部分存在于NUMA机器下面的层次结构中。</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">/sys/devices/system/node</span><br></pre></td></tr></table></figure><p>该目录包含系统上每个NUMA节点的子目录。在节点特定的目录中，有许多文件。对于前两个表中描述的Opteron机器，其重要文件及其内容如表5.4所示。</p><figure><table><tr><th></th><th><code>cpumap</code></th><th><code>distance</code></th></tr><tr><td><code>node0</code></td><td>00000003</td><td>10 20 20 20</td></tr><tr><td><code>node0</code></td><td>0000000c</td><td>20 10 20 20</td></tr><tr><td><code>node2</code></td><td>00000030</td><td>20 20 10 20</td></tr><tr><td><code>node3</code></td><td>000000c0</td><td>20 20 20 10</td></tr></table><figcaption>表 5.4：Opteron 节点的 <code>sysfs</code> 资讯</figcaption></figure><p>这些信息将所有其他信息联系在一起；现在我们已经有了机器架构的完整图像。我们已经知道机器有四个处理器。每个处理器构成自己的节点，如在node*目录中的cpumap文件中的值所示。这些目录中的distance文件包含一组值，每个节点一个，表示在各个节点上的内存访问成本。在这个例子中，所有本地内存访问的成本都是10，所有对任何其他节点的远程访问的成本都是20。<sup class="footnote-ref"><a href="#fn3" id="fnref3">[3]</a></sup> 这意味着，即使处理器被组织成二维超立方体（见图5.1），不直接连接的处理器之间的访问也不会更加昂贵。这些成本的相对值可用作访问时间实际差异的估计。所有这些信息的准确性是另一个问题。</p><h2 id="远端存取成本">远端存取成本</h2><figure><img data-src="/posts/92cd36ac/figure-5.2.webp" alt="图 5.2：多节点的读／写效能"><figcaption>图 5.2：多节点的读／写效能</figcaption></figure><p>不过，距离是有关系的。AMD 在<a href="refer-anchor-1">1</a>中提供了一台四槽机器的NUMA成本。写入操作的数据显示在图 5.2。写入比读取还慢，这并不让人意外。有趣的部分在于 1 与 2 跳（1- and 2-hop）情况下的成本。两个 1 跳的成本实际上有略微不同。细节见 <a href="refer-anchor-1">1</a>。2 跳读取与写入（分别）比 0 跳读取慢了 30% 与 49%。2 跳写入比 0 跳写入慢了 32%、比 1 跳写入慢了 17%。处理器和内存节点的相对位置可能会产生很大的差异。来自AMD的下一代处理器将每个处理器配备四个一致的HyperTransport链接。在这种情况下，四个插槽机器的直径为1。但有八个插槽的话，同样的问题又再次出现，因为具有八个节点的超立方体的直径为三。</p><p>所有这些信息都能够取得，但用起来很麻烦。在 6.5 节，我们会看到较容易存取与使用这个信息的界面。</p><figure><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">00400000 default file=/bin/cat mapped=3 N3=3</span><br><span class="line">00504000 default file=/bin/cat anon=1 dirty=1 mapped=2 N3=2</span><br><span class="line">00506000 default heap anon=3 dirty=3 active=0 N3=3</span><br><span class="line">38a9000000 default file=/lib64/ld-2.4.so mapped=22 mapmax=47 N1=22</span><br><span class="line">38a9119000 default file=/lib64/ld-2.4.so anon=1 dirty=1 N3=1</span><br><span class="line">38a911a000 default file=/lib64/ld-2.4.so anon=1 dirty=1 N3=1</span><br><span class="line">38a9200000 default file=/lib64/libc-2.4.so mapped=53 mapmax=52 N1=51 N2=2</span><br><span class="line">38a933f000 default file=/lib64/libc-2.4.so</span><br><span class="line">38a943f000 default file=/lib64/libc-2.4.so anon=1 dirty=1 mapped=3 mapmax=32 N1=2 N3=1</span><br><span class="line">38a9443000 default file=/lib64/libc-2.4.so anon=1 dirty=1 N3=1</span><br><span class="line">38a9444000 default anon=4 dirty=4 active=0 N3=4</span><br><span class="line">2b2bbcdce000 default anon=1 dirty=1 N3=1</span><br><span class="line">2b2bbcde4000 default anon=2 dirty=2 N3=2</span><br><span class="line">2b2bbcde6000 default file=/usr/lib/locale/locale-archive mapped=11 mapmax=8 N0=11</span><br><span class="line">7fffedcc7000 default stack anon=2 dirty=2 N3=2</span><br></pre></td></tr></table></figure><figcaption>图 5.3：/proc/PID/numa_maps的内容</figcaption></figure><p>系统提供的最后一条信息是进程本身的状态。可以确定内存映射文件、写时复制(COW)<sup class="footnote-ref"><a href="#fn4" id="fnref4">[4]</a></sup>页面和匿名内存在系统中的节点上如何分布。每个进程都有一个文件 <code>/proc/PID/numa_maps</code>，其中PID是进程的ID，如图5.2所示。</p><p>文件中重要的信息是N0到N3的值，它们表示在节点0到3上分配的内存区域的页面数量。很有可能该程序在节点3上的核心上执行，程序本身和脏页面都分配在该节点上。只读映射，如ld-2.4.so和libc-2.4.so的第一个映射以及共享文件locale-archive，则分配在其他节点上。</p><p>如我们在图5.3中所见，对于1和2跳读取，跨节点的读取性能分别下降了9%和30%。对于执行，这些读取是必需的，如果L2缓存未命中，则每个缓存行会产生这些额外的成本。如果内存远离处理器，则所有大型工作负载的成本都将增加9％/30％。</p><figure><img data-src="/posts/92cd36ac/figure-5.4.webp" alt="图 5.4：在远端memory操作"><figcaption>图 5.4：在远端memory操作</figcaption></figure><p>为了看到现实世界中的影响，我们可以像3.5.1节那样测量带宽，但这次是在内存位于远程节点，距离一个跳跃的情况下进行的。将此测试的结果与使用本地内存的数据进行比较，可以在图5.4中看到。这些数字在两个方向上都有一些很大的峰值，这是测量多线程代码的问题，可以忽略不计。这个图表中的重要信息是读操作总是比本地内存慢20%。这比图5.3中的9%要慢得多，这很可能不是连续读写操作的数字，可能指的是旧的处理器版本。只有AMD知道。</p><p>以塞得进cache的工作集大小而言，写入与复制操作的效能也慢了 20%。当工作集大小超过cache大小时，写入效能不再显著地慢于本地节点上的操作。互连的速度足以跟上memory的速度。主要因素是花费在等待主memory的时间。</p><h1 id="参考">参考</h1><div id="refer-anchor-1"></div><ul><li>[1] <a target="_blank" rel="noopener" href="http://www.amd.com/us-en/assets/content_type/white_papers_and_tech_docs/40555.pdf">Performance Guidelines for AMD Athlon™ 64 and AMD Opteron™ ccNUMA Multiprocessor Systems. Advanced Micro Devices</a>, June 2006.</li></ul><div id="refer-anchor-2"></div><ul><li>[2] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/anderson97continuous.html">Jennifer M. Anderson, Lance M. Berc, Jeffrey Dean, Sanjay Ghemawat, Monika R. Henzinger, Shun-Tak A. Leung, Richard L. Sites, Mark T. Vandevoorde, Carl A. Waldspurger, and William E. Weihl. Continuous profiling: Where have all the cycles gone. In Proceedings of the 16th ACM Symposium of Operating Systems Principles, pages 1–14</a>, October 1997.</li></ul><div id="refer-anchor-3"></div><ul><li>[3] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/476689.html">Vinodh Cuppu, Bruce Jacob, Brian Davis, and Trevor Mudge. High-Performance DRAMs in Workstation Environments. IEEE Transactions on Computers, 50(11):1133–1153</a>, November 2001.</li></ul><div id="refer-anchor-4"></div><ul><li>[4] <a target="_blank" rel="noopener" href="https://ols2006.108.redhat.com/2007/Reprints/melo-Reprint.pdf">Arnaldo Carvalho de Melo. The 7 dwarves: debugging information beyond gdb. In Proceedings of the Linux Symposium</a>, 2007.</li></ul><div id="refer-anchor-5"></div><ul><li>[5] <a target="_blank" rel="noopener" href="http://research.sun.com/scalable/pubs/SPAA04.pdf">Simon Doherty, David L. Detlefs, Lindsay Grove, Christine H. Flood, Victor Luchangco, Paul A. Martin, Mark Moir, Nir Shavit, and Jr. Guy L. Steele. DCAS is not a Silver Bullet for Nonblocking Algorithm Design. In SPAA ’04: Proceedings of the Sixteenth Annual ACM Symposium on Parallelism in Algorithms and Architectures, pages 216–224, New York, NY, USA, 2004. ACM Press. ISBN 1-58113-840-7</a>.</li></ul><div id="refer-anchor-6"></div><ul><li>[6] <a target="_blank" rel="noopener" href="http://www.pcstats.com/articleview.cfm?articleID=1573">M. Dowler. Introduction to DDR-2: The DDR Memory Replacement</a>, May 2004.</li></ul><div id="refer-anchor-7"></div><ul><li>[7] <a target="_blank" rel="noopener" href="http://people.redhat.com/drepper/futex.pdf">Ulrich Drepper. Futexes Are Tricky</a>, December 2005</li></ul><div id="refer-anchor-8"></div><ul><li>[8] <a target="_blank" rel="noopener" href="http://people.redhat.com/drepper/tls.pdf">Ulrich Drepper. ELF Handling For Thread-Local Storage. Technical report, Red Hat, Inc</a>, 2003.</li></ul><div id="refer-anchor-9"></div><ul><li>[9] <a target="_blank" rel="noopener" href="http://people.redhat.com/drepper/nonselsec.pdf">Ulrich Drepper. Security Enhancements in Red Hat Enterprise Linux</a>, 2004.</li></ul><div id="refer-anchor-10"></div><ul><li>[10] <a target="_blank" rel="noopener" href="http://www.grame.fr/pub/fober-JIM2002.pdf">Dominique Fober, Yann Orlarey, and Stephane Letz. Lock-Free Techiniques for Concurrent Access to Shared Objects. In GMEM, editor, Actes des Journes d’Informatique Musicale JIM2002, Marseille, pages 143–150</a>,2002.</li></ul><div id="refer-anchor-11"></div><ul><li>[11] Joe Gebis and David Patterson. Embracing and Extending 20th-Century Instruction Set Architectures. Computer, 40(4):68–75, April 2007. 8.4</li></ul><div id="refer-anchor-12"></div><ul><li>[12] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/goldberg91what.html">David Goldberg. What Every Computer Scientist Should Know About Floating-Point Arithmetic. ACM Computing Surveys, 23(1):5–48</a>, March 1991.</li></ul><div id="refer-anchor-13"></div><ul><li>[13] <a target="_blank" rel="noopener" href="http://citeseer.ist.psu.edu/herlihy93transactional.html">Maurice Herlihy and J. Eliot B. Moss. Transactional memory: Architectural support for lock-free data structures. In Proceedings of 20th International Symposium on Computer Architecture</a>, 1993.</li></ul><div id="refer-anchor-14"></div><ul><li>[14] <a target="_blank" rel="noopener" href="http://www.stanford.edu/group/comparch/papers/huggahalli05.pdf">Ram Huggahalli, Ravi Iyer, and Scott Tetrick. Direct Cache Access for High Bandwidth Network I/O</a>, 2005.</li></ul><div id="refer-anchor-15"></div><ul><li>[15] <a target="_blank" rel="noopener" href="http://www.intel.com/design/processor/manuals/248966.pdf">Intel R© 64 and IA-32 Architectures Optimization Reference Manual. Intel Corporation</a>, May 2007.</li></ul><div id="refer-anchor-16"></div><ul><li>[16] <a href="ftp://download.intel.com/technology/itj/2002/volume06issue01/art06_computeintensive/vol6iss1_art06">William Margo, Paul Petersen, and Sanjiv Shah. Hyper-Threading Technology: Impact on Compute-Intensive Workloads. Intel Technology Journal, 6(1)</a>, 2002.</li></ul><div id="refer-anchor-17"></div><ul><li>[17] <a target="_blank" rel="noopener" href="http://blogs.linux.ie/caolan/2007/04/24/controlling-symbol-ordering/">Caol ́an McNamara. Controlling symbol ordering</a>, April 2007.</li></ul><div id="refer-anchor-18"></div><ul><li>[18] Double Data Rate (DDR) SDRAM MT46V. Micron Technology, 2003. Rev. L 6/06 EN.</li></ul><div id="refer-anchor-19"></div><ul><li>[19] <a target="_blank" rel="noopener" href="http://arstechnica.com/paedia/r/ram_guide/ram_guide.part2-1.html">Jon “Hannibal” Stokes. Ars Technica RAM Guide, Part II: Asynchronous and Synchronous DRAM</a>, 2004.</li></ul><div id="refer-anchor-20"></div><ul><li>[20] <a target="_blank" rel="noopener" href="http://en.wikipedia.org/wiki/Static_Random_Access_Memory">Static random access memory - Wikipedia</a>, 2006.</li></ul><hr class="footnotes-sep"><section class="footnotes"><ol class="footnotes-list"><li id="fn1" class="footnote-item"><p>x86的分段限制是与性能相关的，但那是另一回事了 <a href="#fnref1" class="footnote-backref">↩︎</a></p></li><li id="fn2" class="footnote-item"><p>cpu0到cpu3是核心的信息来自另一个即将介绍的地方 <a href="#fnref2" class="footnote-backref">↩︎</a></p></li><li id="fn3" class="footnote-item"><p>顺便说一句，这是错误的。ACPI信息显然是错误的，因为虽然使用的处理器具有三个一致的HyperTransport链接，但至少一个处理器必须连接到Southbridge。因此，至少有一对节点必须有更大的距离。 <a href="#fnref3" class="footnote-backref">↩︎</a></p></li><li id="fn4" class="footnote-item"><p>写时复制是操作系统实现中经常使用的一种方法，当一个内存页一开始只有一个用户时，然后必须复制以允许独立的用户。在许多情况下，复制是不必要的，或者起初是不必要的，在这种情况下，只有当任一用户修改内存时才有意义。操作系统拦截写操作，复制内存页，然后允许写指令继续进行。 <a href="#fnref4" class="footnote-backref">↩︎</a></p></li></ol></section></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/420ccca2/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/420ccca2/" class="post-title-link" itemprop="url">Ubuntu环境编译openjdk</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-07-03 16:39:19" itemprop="dateCreated datePublished" datetime="2020-07-03T16:39:19+08:00">2020-07-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-27 14:53:33" itemprop="dateModified" datetime="2024-06-27T14:53:33+08:00">2024-06-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Java/" itemprop="url" rel="index"><span itemprop="name">Java</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Java/JDK/" itemprop="url" rel="index"><span itemprop="name">JDK</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/420ccca2/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/420ccca2/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/420ccca2/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>6.4k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>11 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><ul><li>ubuntu 环境: 20.04</li><li>jdk 版本: openjdk-8</li></ul><h1 id="源码下载">源码下载</h1><p>openjdk的源码可以从github中获取:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> https://github.com/openjdk/jdk.git</span><br><span class="line">git checkout jdk8-b120</span><br><span class="line">git checkout -b tag-jdk8-b120</span><br></pre></td></tr></table></figure><p>国内码云上有同步的镜像仓库:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">git <span class="built_in">clone</span> git@gitee.com:mirrors/openjdk.git</span><br></pre></td></tr></table></figure><h1 id="源码编译">源码编译</h1><h2 id="安装依赖">安装依赖</h2><p>运行configure前先安装一些依赖:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install gcc g++ gdb make build-essential cpio libasound2-dev libfreetype6-dev libcups2-dev libfontconfig1-dev libxext-dev libxrender-dev libxtst-dev libxt-dev libffi-dev</span><br></pre></td></tr></table></figure><h2 id="configure">configure</h2><p>执行configure</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash configure</span><br></pre></td></tr></table></figure><p>configure会检查项目依赖，如果有缺失的，按照提示安装即可。</p><h3 id="Boot-JDK">Boot JDK</h3><p>JDK的编译需要“版本-1”的JDK，例如在编译JDK8时，会提示:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">configure: Could not find a valid Boot JDK. You might be able to fix this by running &#x27;sudo apt-get install openjdk-7-jdk&#x27;.</span><br></pre></td></tr></table></figure><p>由于当前源不包含openjdk7,直接使用jdk8进行编译</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">bash configure --with-boot-jdk=/home/victorchutian/.sdkman/candidates/java/8.0.282-open</span><br></pre></td></tr></table></figure><h3 id="freeType">freeType</h3><p>参考<a target="_blank" rel="noopener" href="https://stackoverflow.com/questions/52377684/compile-jdk8-error-could-not-find-freetype">stackoverflow</a>增加编译参数:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bash configure \</span><br><span class="line">--with-boot-jdk=/home/victorchutian/.sdkman/candidates/java/8.0.282-open \</span><br><span class="line">--with-freetype-include=/usr/include/freetype2 \</span><br><span class="line">--with-freetype-lib=/usr/lib/x86_64-linux-gnu \</span><br></pre></td></tr></table></figure><h3 id="最终参数">最终参数</h3><p>configure最终参数为:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">bash configure \</span><br><span class="line">--with-boot-jdk=/home/victorchutian/.sdkman/candidates/java/8.0.282-open \</span><br><span class="line">--with-freetype-include=/usr/include/freetype2 \</span><br><span class="line">--with-freetype-lib=/usr/lib/x86_64-linux-gnu \</span><br><span class="line">--with-target-bits=64 \</span><br><span class="line">--with-debug-level=slowdebug \</span><br><span class="line">--with-jvm-variants=server \</span><br><span class="line">--enable-debug-symbols</span><br></pre></td></tr></table></figure><h2 id="make">make</h2><p>接下来就是编译：</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">make all</span><br></pre></td></tr></table></figure><h3 id="OS-is-not-supported">OS is not supported</h3><p>编译报错：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">*** This OS is not supported: Linux 9c888f853395 5.19.0-43-generic #44~22.04.1-Ubuntu SMP PREEMPT_DYNAMIC Mon May 22 13:39:36 UTC 2 x86_64 x86_64 x86_64 GNU/Linux</span><br></pre></td></tr></table></figure><p>修改Makefile</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># hotspot/make/linux/Makefile</span></span><br><span class="line">SUPPORTED_OS_VERSION = 2.4% 2.5% 2.6% 3% 4% 5%</span><br></pre></td></tr></table></figure><h3 id="usr-bin-make-invalid-option"><code>/usr/bin/make: invalid option -- '/'</code></h3><p>修改hotspot/make/linux/makefiles/adjust-mflags.sh文件</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">@@ -64,7 +64,7 @@</span><br><span class="line">    <span class="built_in">echo</span> <span class="string">&quot;<span class="variable">$MFLAGS</span>&quot;</span> \</span><br><span class="line">    | sed <span class="string">&#x27;</span></span><br><span class="line"><span class="string">        s/^-/ -/</span></span><br><span class="line"><span class="string">-       s/ -\([^    ][^     ]*\)j/ -\1 -j/</span></span><br><span class="line"><span class="string">+       s/ -\([^    I][^    I]*\)j/ -\1 -j/</span></span><br><span class="line"><span class="string">        s/ -j[0-9][0-9]*/ -j/</span></span><br><span class="line"><span class="string">        s/ -j\([^   ]\)/ -j -\1/</span></span><br><span class="line"><span class="string">        s/ -j/ -j&#x27;</span><span class="variable">$&#123;HOTSPOT_BUILD_JOBS:-<span class="variable">$&#123;default_build_jobs&#125;</span>&#125;</span><span class="string">&#x27;/</span></span><br></pre></td></tr></table></figure><h3 id="all-warnings-being-treated-as-errors"><code>all warnings being treated as errors</code></h3><p>hotspot/make/linux/makefiles/gcc.make,200行左右：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">WARNINGS_ARE_ERRORS=-Werror</span><br><span class="line">改为</span><br><span class="line">WARNINGS_ARE_ERRORS=-Wno-error</span><br></pre></td></tr></table></figure><h3 id="语法错误">语法错误</h3><p>重新编译后还是有大量语法错误。将gcc版本控制在5.0以下，见<a target="_blank" rel="noopener" href="https://hg.openjdk.org/jdk8u/jdk8u/raw-file/tip/README-builds.html#buildenvironments">jdk8最小构建环境</a></p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">sudo apt install gcc-4.8 g++-4.8</span><br></pre></td></tr></table></figure><p>如果出现Package ‘gcc-4.8’ has no installation candidate</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># vim /etc/apt/sources.list</span></span><br><span class="line">deb http://dk.archive.ubuntu.com/ubuntu xenial main</span><br><span class="line">deb http://dk.archive.ubuntu.com/ubuntu xenial universe</span><br><span class="line">apt update</span><br></pre></td></tr></table></figure><p>设置gcc为4.8版本的gcc</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 配置新安装的gcc 4.8的启动优先级为100</span></span><br><span class="line">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-4.8 100</span><br><span class="line"><span class="comment"># 配置新安装的g++ 4.8的启动优先级为100</span></span><br><span class="line">sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-4.8 100</span><br></pre></td></tr></table></figure><p>然后重新运行configure,继续编译。</p><h3 id="class-jdk-nashorn-internal-objects-ScriptFunctionImpl-overrides-final-method-setPrototype"><code>class jdk.nashorn.internal.objects.ScriptFunctionImpl overrides final method setPrototype</code></h3><p>修改nashorn/make/BuildNashorn.gmk文件，修改前：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">73 # Copy classes to final classes dir and run nasgen to modify classes in jdk.nashorn.internal.objects package</span><br><span class="line">74 $(NASHORN_OUTPUTDIR)/classes/_the.nasgen.run: $(BUILD_NASGEN)</span><br><span class="line">75         $(ECHO) Running nasgen</span><br><span class="line">76         $(MKDIR) -p $(@D)</span><br><span class="line">77         $(RM) -rf $(@D)/jdk $(@D)/netscape</span><br><span class="line">78         $(CP) -R -p $(NASHORN_OUTPUTDIR)/nashorn_classes/* $(@D)/</span><br><span class="line">79         $(FIXPATH) $(JAVA) \</span><br><span class="line">80             -cp &quot;$(NASHORN_OUTPUTDIR)/nasgen_classes$(PATH_SEP)$(NASHORN_OUTPUTDIR)/nashorn_classes&quot; \</span><br><span class="line">81             jdk.nashorn.internal.tools.nasgen.Main $(@D) jdk.nashorn.internal.objects $(@D)</span><br><span class="line">82         $(TOUCH) $@</span><br><span class="line">83</span><br></pre></td></tr></table></figure><p>修改第80行，修改后：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">73 # Copy classes to final classes dir and run nasgen to modify classes in jdk.nashorn.internal.objects package</span><br><span class="line">74 $(NASHORN_OUTPUTDIR)/classes/_the.nasgen.run: $(BUILD_NASGEN)</span><br><span class="line">75         $(ECHO) Running nasgen</span><br><span class="line">76         $(MKDIR) -p $(@D)</span><br><span class="line">77         $(RM) -rf $(@D)/jdk $(@D)/netscape</span><br><span class="line">78         $(CP) -R -p $(NASHORN_OUTPUTDIR)/nashorn_classes/* $(@D)/</span><br><span class="line">79         $(FIXPATH) $(JAVA) \</span><br><span class="line">80             -Xbootclasspath/p:&quot;$(NASHORN_OUTPUTDIR)/nasgen_classes$(PATH_SEP)$(NASHORN_OUTPUTDIR)/nashorn_classes&quot; \</span><br><span class="line">81             jdk.nashorn.internal.tools.nasgen.Main $(@D) jdk.nashorn.internal.objects $(@D)</span><br><span class="line">82         $(TOUCH) $@</span><br><span class="line">83</span><br></pre></td></tr></table></figure><h2 id="编译完成">编译完成</h2><p>最后可以看到编译完成的日志:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">#  Finished docs (build time 00:00:43)</span><br><span class="line"></span><br><span class="line">----- Build times -------</span><br><span class="line">Start 2020-07-03 01:06:25</span><br><span class="line">End   2020-07-03 01:09:40</span><br><span class="line">00:00:09 corba</span><br><span class="line">00:00:05 demos</span><br><span class="line">00:00:43 docs</span><br><span class="line">00:00:48 hotspot</span><br><span class="line">00:00:07 images</span><br><span class="line">00:00:06 jaxp</span><br><span class="line">00:00:08 jaxws</span><br><span class="line">00:00:53 jdk</span><br><span class="line">00:00:12 langtools</span><br><span class="line">00:00:04 nashorn</span><br><span class="line">00:03:15 TOTAL</span><br></pre></td></tr></table></figure><p>执行java命令:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">$ ./build/linux-x86_64-normal-server-slowdebug/jdk/bin/java -version</span><br><span class="line">openjdk version <span class="string">&quot;1.8.0-internal-debug&quot;</span></span><br><span class="line">OpenJDK Runtime Environment (build 1.8.0-internal-debug-victorchutian_2020_07_03_18_32-b00)</span><br><span class="line">OpenJDK 64-Bit Server VM (build 25.0-b62-debug, mixed mode)</span><br><span class="line">victorchutian@9c888f853395:~/projects/openjdk$ </span><br></pre></td></tr></table></figure><h1 id="vscode">vscode</h1><h2 id="launch-json">launch.json</h2><p>launch.json配置如下</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="comment">// Use IntelliSense to learn about possible attributes.</span></span><br><span class="line">    <span class="comment">// Hover to view descriptions of existing attributes.</span></span><br><span class="line">    <span class="comment">// For more information, visit: https://go.microsoft.com/fwlink/?linkid=830387</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="string">&quot;0.2.0&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;(gdb) Launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;cppdbg&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;request&quot;</span><span class="punctuation">:</span> <span class="string">&quot;launch&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;program&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/build/linux-x86_64-normal-server-slowdebug/jdk/bin/java&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;args&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="string">&quot;-version&quot;</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;stopAtEntry&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span> <span class="comment">//设置debug停住</span></span><br><span class="line">            <span class="attr">&quot;cwd&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;environment&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;externalConsole&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;MIMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;miDebuggerPath&quot;</span><span class="punctuation">:</span><span class="string">&quot;/usr/bin/gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;setupCommands&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="punctuation">&#123;</span></span><br><span class="line">                    <span class="attr">&quot;description&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Enable pretty-printing for gdb&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;text&quot;</span><span class="punctuation">:</span> <span class="string">&quot;-enable-pretty-printing&quot;</span><span class="punctuation">,</span></span><br><span class="line">                    <span class="attr">&quot;ignoreFailures&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span></span><br><span class="line">                <span class="punctuation">&#125;</span></span><br><span class="line">            <span class="punctuation">]</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h2 id="c-cpp-properties-json">c_cpp_properties.json</h2><p>vscode cpp插件需要c_cpp_properties.json.</p><p>首先安装<a target="_blank" rel="noopener" href="https://github.com/nickdiego/compiledb">compiledb</a>。然后使用<code>compiledb make all</code>编译。然后会在项目根目录下生成文件<code>compile_commands.json</code>。将其中的 -D 后的所有参数收集起来，然后将收集起来的参数添加到 c_cpp_properties.json 中的 define 配置中。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;configurations&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="string">&quot;Linux&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;includePath&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;$&#123;workspaceFolder&#125;/**&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;defines&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;LINUX&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;_GNU_SOURCE&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;AMD64&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;ASSERT&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;TARGET_OS_FAMILY_linux&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;TARGET_ARCH_x86&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;TARGET_ARCH_MODEL_x86_64&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;TARGET_OS_ARCH_linux_x86&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;TARGET_OS_ARCH_MODEL_linux_x86_64&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;TARGET_COMPILER_gcc&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;COMPILER2&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;COMPILER1&quot;</span><span class="punctuation">,</span></span><br><span class="line">                <span class="string">&quot;_REENTRANT&quot;</span></span><br><span class="line">            <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;compilerPath&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/usr/bin/g++&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cStandard&quot;</span><span class="punctuation">:</span> <span class="string">&quot;c11&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;cppStandard&quot;</span><span class="punctuation">:</span> <span class="string">&quot;c++14&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;intelliSenseMode&quot;</span><span class="punctuation">:</span> <span class="string">&quot;linux-gcc-x64&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;compileCommands&quot;</span><span class="punctuation">:</span> <span class="string">&quot;$&#123;workspaceFolder&#125;/compile_commands.json&quot;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">    <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">    <span class="attr">&quot;version&quot;</span><span class="punctuation">:</span> <span class="number">4</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><h1 id="参考资料">参考资料</h1><ul><li>[1] <a target="_blank" rel="noopener" href="https://hg.openjdk.org/jdk8u/jdk8u/raw-file/tip/README-builds.html">OpenJDK8 README-builds</a></li><li>[2] <a target="_blank" rel="noopener" href="https://jiawanggjia.github.io/post/openjdk-bian-yi-zhi-nan/">OpenJDK 编译指南(Ubuntu 16.04 + MacOS 10.15)</a></li></ul></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/4eea1c75/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/4eea1c75/" class="post-title-link" itemprop="url">使用update-alternatives切换GCC版本</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-07-03 15:00:59" itemprop="dateCreated datePublished" datetime="2020-07-03T15:00:59+08:00">2020-07-03</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-27 14:53:33" itemprop="dateModified" datetime="2024-06-27T14:53:33+08:00">2024-06-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Shell/" itemprop="url" rel="index"><span itemprop="name">Shell</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/4eea1c75/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/4eea1c75/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/4eea1c75/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>2.2k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>4 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>首先在ubuntu上安装多版本的GCC:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">$ sudo apt install build-essential</span><br><span class="line">$ sudo apt -y install gcc-7 g++-7 gcc-8 g++-8 gcc-9 g++-9</span><br></pre></td></tr></table></figure><p>然后使用<code>update-alternatives</code>注册不同版本的GCC:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-7 7</span><br><span class="line">sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-7 7</span><br><span class="line">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-8 8</span><br><span class="line">sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-8 8</span><br><span class="line">sudo update-alternatives --install /usr/bin/gcc gcc /usr/bin/gcc-9 9</span><br><span class="line">sudo update-alternatives --install /usr/bin/g++ g++ /usr/bin/g++-9 9</span><br></pre></td></tr></table></figure><p>选择想使用的GCC:</p><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">$ sudo update-alternatives --config gcc</span><br><span class="line">There are 3 choices <span class="keyword">for</span> the alternative gcc (providing /usr/bin/gcc).</span><br><span class="line"></span><br><span class="line">  Selection    Path            Priority   Status</span><br><span class="line">------------------------------------------------------------</span><br><span class="line">  0            /usr/bin/gcc-9   9         auto mode</span><br><span class="line">  1            /usr/bin/gcc-7   7         manual mode</span><br><span class="line">* 2            /usr/bin/gcc-8   8         manual mode</span><br><span class="line">  3            /usr/bin/gcc-9   9         manual mode</span><br><span class="line">Press  to keep the current choice[*], or <span class="built_in">type</span> selection number: </span><br></pre></td></tr></table></figure><div class="post-button"><a class="btn" href="/posts/4eea1c75/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/8a15ea5f/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/8a15ea5f/" class="post-title-link" itemprop="url">缓存的一些思考</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-26 20:50:00" itemprop="dateCreated datePublished" datetime="2020-05-26T20:50:00+08:00">2020-05-26</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2025-01-02 16:49:30" itemprop="dateModified" datetime="2025-01-02T16:49:30+08:00">2025-01-02</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Architecture/" itemprop="url" rel="index"><span itemprop="name">Architecture</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Architecture/Cache/" itemprop="url" rel="index"><span itemprop="name">Cache</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/8a15ea5f/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/8a15ea5f/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/8a15ea5f/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>3.1k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>5 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>缓存常被用于处理高并发,高性能问题,在现今的系统中被广泛使用。缓存模式，简单来说就是利用时间局限性原理，通过空间换时间来达到加速数据获取的目的。</p><p>缓存的读写性能很高，预热快，在数据访问存在性能瓶颈或遇到突发流量，系统读写压力大增时，可以快速部署上线，同时在流量稳定后，也可以随时下线，从而使系统的可扩展性大大增强。</p><p>但是，在系统中引入缓存后，会增加系统的复杂度。</p><div class="post-button"><a class="btn" href="/posts/8a15ea5f/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/f9aa8120/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/f9aa8120/" class="post-title-link" itemprop="url">Apache Flink™: Stream and Batch Processing in a Single Engine</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-25 20:50:00" itemprop="dateCreated datePublished" datetime="2020-05-25T20:50:00+08:00">2020-05-25</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-27 14:53:33" itemprop="dateModified" datetime="2024-06-27T14:53:33+08:00">2024-06-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/BigData/" itemprop="url" rel="index"><span itemprop="name">BigData</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/f9aa8120/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/f9aa8120/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/f9aa8120/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>15k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>25 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本篇是<a target="_blank" rel="noopener" href="http://asterios.katsifodimos.com/assets/publications/flink-deb.pdf">论文</a>的中文简单翻译</p></blockquote><p>Apache Flink 是一个开放源代码系统，用于处理流数据和批处理数据。Flink的哲学是，许多类别的数据处理应用程序（包括实时分析，数据管道，历史数据处理（批处理）和迭代算法（机器学习，图形分析）都可以表示为容错的流水线数据流并执行。在本文中，我们提出Flink的体系结构，并就如何在单一执行模型下执行一组多样性用例进行扩展分析。</p><div class="post-button"><a class="btn" href="/posts/f9aa8120/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/4eb3381c/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/4eb3381c/" class="post-title-link" itemprop="url">分布式锁简介</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-25 11:09:22" itemprop="dateCreated datePublished" datetime="2020-05-25T11:09:22+08:00">2020-05-25</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-27 14:53:33" itemprop="dateModified" datetime="2024-06-27T14:53:33+08:00">2024-06-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Distributed/" itemprop="url" rel="index"><span itemprop="name">Distributed</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Distributed/Lock/" itemprop="url" rel="index"><span itemprop="name">Lock</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/4eb3381c/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/4eb3381c/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/4eb3381c/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>22k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>37 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><p>在分布式场景中分布式锁是一种很常见的需求。实现一个分布式锁要注意以下几点:</p><ul><li>安全: 独享（相互排斥）。在任意一个时刻，只有一个客户端持有锁。</li><li>锁失效保护: 无死锁。即便持有锁的客户端崩溃（crashed)或者网络被分裂（gets partitioned)，锁仍然可以被获取。</li><li>集群容错。 只要大部分节点都活着，客户端就可以获取和释放锁。</li><li>原子性：获取释放锁最好是原子操作，获取释放锁的性能要好。</li><li>可重入(optional): 同一个线程在没有释放锁之前，如果想再次操作，可以直接获得锁。</li><li>阻塞/非阻塞(optional)：若没有获取到锁，返回获取失败。</li></ul><div class="post-button"><a class="btn" href="/posts/4eb3381c/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/85a42be3/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/85a42be3/" class="post-title-link" itemprop="url">Dataflow 模型：一种能平衡准确性、延迟、成本的大规模、无限、乱序的数据处理的实践方法</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-23 15:45:10" itemprop="dateCreated datePublished" datetime="2020-05-23T15:45:10+08:00">2020-05-23</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-27 14:53:33" itemprop="dateModified" datetime="2024-06-27T14:53:33+08:00">2024-06-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/BigData/" itemprop="url" rel="index"><span itemprop="name">BigData</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/85a42be3/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/85a42be3/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/85a42be3/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>23k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>38 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本篇是<a target="_blank" rel="noopener" href="https://www.vldb.org/pvldb/vol8/p1792-Akidau.pdf">论文</a>的中文简单翻译</p></blockquote><h1 id="概述">概述</h1><p>在日常商业运营中，无边界、乱序、大规模数据集越来越普遍了。（例如，网站日志，手机应用统计，传感器网络）。同时，对这些数据的消费需求也越来越复杂。比如说按事件发生时间序列处理数据，按数据本身的特征进行窗口计算等等。同时人们也越来越苛求立刻得到数据分析结果。然而，实践表明，我们永远无法同时优化数据处理的准确性、延迟程度和处理成本等各个维度。因此，数据工作者面临如何协调这些几乎相互冲突的数据处理技术指标的窘境，设计出来各种纷繁的数据处理系统和实践方法。</p><p>我们建议数据处理的方法必须进行根本性的改进。作为数据工作者，我们不能把无边界数据集（数据流）切分成有边界的数据，等待一个批次完整后处理。相反地，我们应该假设我们永远无法知道数据流是否终结，何时数据会变完整。唯一应该确信的是，新的数据会源源不断而来，老的数据可能会被撤销或更新。而能够让数据工作者应对这个挑战的唯一可行的方法是通过一个遵守原则的抽象来平衡折衷取舍数据处理的准确性、延迟程度和处理成本。</p><p>在这篇论文中，我们提出了Dataflow模型，并详细地阐述了它的语义，设计的核心原则，以及在实践开发过程中对模型的检验。</p><div class="post-button"><a class="btn" href="/posts/85a42be3/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><div class="post-block"><article itemscope itemtype="http://schema.org/Article" class="post-content"><link itemprop="mainEntityOfPage" href="https://www.victorchu.info/posts/6fd40c2d/"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="image" content="/images/victor-blog-head.webp"><meta itemprop="name" content="Victor Chu"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="代码之旅"><meta itemprop="description" content="blog about programming."></span><span hidden itemprop="post" itemscope itemtype="http://schema.org/CreativeWork"><meta itemprop="name" content="undefined | 代码之旅"><meta itemprop="description" content=""></span><header class="post-header"><h2 class="post-title" itemprop="name headline"><a href="/posts/6fd40c2d/" class="post-title-link" itemprop="url">MapReduce面向大型集群的简化数据处理</a></h2><div class="post-meta-container"><div class="post-meta"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建时间：2020-05-18 20:50:00" itemprop="dateCreated datePublished" datetime="2020-05-18T20:50:00+08:00">2020-05-18</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-calendar-check"></i> </span><span class="post-meta-item-text">更新于</span> <time title="修改时间：2024-06-27 14:53:33" itemprop="dateModified" datetime="2024-06-27T14:53:33+08:00">2024-06-27</time> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-folder"></i> </span><span class="post-meta-item-text">分类于</span> <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/" itemprop="url" rel="index"><span itemprop="name">Paper</span></a> </span>， <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/Paper/BigData/" itemprop="url" rel="index"><span itemprop="name">BigData</span></a> </span></span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="far fa-comment"></i> </span><span class="post-meta-item-text">Waline：</span> <a title="waline" href="/posts/6fd40c2d/#waline" itemprop="discussionUrl"><span class="post-comments-count waline-comment-count" data-path="/posts/6fd40c2d/" itemprop="commentCount"></span> </a></span><span class="post-meta-item" title="阅读次数"><span class="post-meta-item-icon"><i class="far fa-eye"></i> </span><span class="post-meta-item-text">阅读次数：</span> <span class="waline-pageview-count" data-path="/posts/6fd40c2d/"></span> </span><span class="post-meta-break"></span> <span class="post-meta-item" title="本文字数"><span class="post-meta-item-icon"><i class="far fa-file-word"></i> </span><span class="post-meta-item-text">本文字数：</span> <span>11k</span> </span><span class="post-meta-item" title="阅读时长"><span class="post-meta-item-icon"><i class="far fa-clock"></i> </span><span class="post-meta-item-text">阅读时长 &asymp;</span> <span>19 分钟</span></span></div></div></header><div class="post-body" itemprop="articleBody"><blockquote><p>本篇是<a target="_blank" rel="noopener" href="https://pdos.csail.mit.edu/6.824/papers/mapreduce.pdf">论文</a>的中文简单翻译</p></blockquote><p>什么是MapReduce？</p><p><strong>MapReduce既是一种编程模型，也是一种用于处理和产生大数据集的实现</strong>。用户使用一个特定的map程序去处理key/value对，并产生中间key/value对的集合，以及一个特定的reduce程序去合并有着相同key的所有中间key/value对。本文指出，许多实际的任务都可以用这种模型来表示。</p><p><strong>用这种函数式风格写出的程序自动就拥有了在一个大的机器集群上并行执行的能力</strong>。运行时系统会负责细节：输入数据分区，在一组机器上执行调度程序，处理机器错误，以及管理所需的机器间内部通信。这允许不具备任何并行和分布式系统经验的程序员也能轻松地利用一个大型分布式系统的资源。</p><div class="post-button"><a class="btn" href="/posts/6fd40c2d/#more" rel="contents">阅读全文 &raquo;</a></div></div><footer class="post-footer"><div class="post-eof"></div></footer></article></div><nav class="pagination"><a class="extend prev" rel="prev" title="上一页" aria-label="上一页" href="/page/8/"><i class="fa fa-angle-left"></i></a><a class="page-number" href="/">1</a><span class="space">&hellip;</span><a class="page-number" href="/page/8/">8</a><span class="page-number current">9</span><a class="page-number" href="/page/10/">10</a><span class="space">&hellip;</span><a class="page-number" href="/page/23/">23</a><a class="extend next" rel="next" title="下一页" aria-label="下一页" href="/page/10/"><i class="fa fa-angle-right"></i></a></nav></div></main><footer class="footer"><div class="footer-inner"><div class="beian"><a href="https://beian.miit.gov.cn/" rel="noopener" target="_blank">浙ICP备18037908号-1 </a><img src="/images/gongan_icon.webp" alt=""><a href="https://beian.mps.gov.cn/#/query/webSearch?code=33010902002043" rel="noopener" target="_blank">浙公网安备 33010902002043号</a></div><div class="copyright">&copy; 2016 – <span itemprop="copyrightYear">2025</span> <span class="with-love"><i class="fa fa-heart"></i> </span><span class="author" itemprop="copyrightHolder">Victor Chu</span></div><div class="wordcount"><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-chart-line"></i> </span><span title="站点总字数">1.9m</span> </span><span class="post-meta-item"><span class="post-meta-item-icon"><i class="fa fa-coffee"></i> </span><span title="站点阅读时长">53:49</span></span></div><div class="powered-by">由<a href="https://www.upyun.com/?utm_source=lianmeng&utm_medium=referral" class="theme-link" rel="noopener" target="_blank"><img src="/images/upyun_logo.webp" width="50" style="display:inline"></a>提供CDN服务</div></div></footer><div class="toggle sidebar-toggle" role="button"><span class="toggle-line"></span> <span class="toggle-line"></span> <span class="toggle-line"></span></div><div class="sidebar-dimmer"></div><div class="reading-progress-bar"></div><a role="button" class="book-mark-link book-mark-link-fixed"></a><noscript><div class="noscript-warning">Theme NexT works best with JavaScript enabled</div></noscript><script src="https://cdnjs.cloudflare.com/ajax/libs/animejs/3.2.1/anime.min.js" integrity="sha256-XL2inqUJaslATFnHdJOi9GfQ60on8Wx1C2H8DYiN1xY=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fancyapps-ui/5.0.31/fancybox/fancybox.umd.js" integrity="sha256-a+H7FYzJv6oU2hfsfDGM2Ohw/cR9v+hPfxHCLdmCrE8=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/lozad.js/1.16.0/lozad.min.js" integrity="sha256-mOFREFhqmHeQbXpK2lp4nA3qooVgACfh88fpJftLBbc=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/pangu/4.0.7/pangu.min.js" integrity="sha256-j+yj56cdEY2CwkVtGyz18fNybFGpMGJ8JxG3GSyO2+I=" crossorigin="anonymous"></script><script src="/js/comments.js"></script><script src="/js/utils.js"></script><script src="/js/motion.js"></script><script src="/js/schemes/muse.js"></script><script src="/js/sidebar.js"></script><script src="/js/next-boot.js"></script><script src="/js/bookmark.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/algoliasearch/4.23.3/algoliasearch-lite.umd.js" integrity="sha256-1QNshz86RqXe/qsCBldsUu13eAX6n/O98uubKQs87UI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/instantsearch.js/4.67.0/instantsearch.production.min.js" integrity="sha256-TW7D3X/i/W+RUgEeDppEnFT2ixv5lzplKH0c58D92dY=" crossorigin="anonymous"></script><script src="/js/third-party/search/algolia-search.js"></script><script class="next-config" data-name="mermaid" type="application/json">{"enable":true,"theme":"dark","js":{"url":"https://cdnjs.cloudflare.com/ajax/libs/mermaid/10.9.0/mermaid.min.js","integrity":"sha256-stuqcu2FrjYCXDOytWFA5SoUE/r3nkp6gTglzNSlavU="}}</script><script src="/js/third-party/tags/mermaid.js"></script><script src="/js/third-party/fancybox.js"></script><script src="/js/third-party/pace.js"></script><script src="/js/third-party/addtoany.js"></script><script class="next-config" data-name="enableMath" type="application/json">true</script><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.9/katex.min.css" integrity="sha256-UF1fgpAiu3tPJN/uCqEUHNe7pnr+QR0SQDNfgglgtcM=" crossorigin="anonymous"><script class="next-config" data-name="waline" type="application/json">{"lang":"zh-cn","enable":true,"serverURL":"walineui.victorchu.info","cssUrl":"https://cdn.staticfile.org/waline/2.15.8/waline.css","commentCount":true,"pageview":true,"requiredMeta":["nick","mail"],"login":"force","libUrl":"https://cdn.staticfile.org/waline/2.15.8/waline.js","dark":"body.darkmode--activated","el":"#waline","comment":true,"path":"/page/9/"}</script><link rel="stylesheet" href="https://cdn.staticfile.org/waline/2.15.8/waline.css"><script>document.addEventListener('page:loaded', () => {
  NexT.utils.loadComments(CONFIG.waline.el).then(() =>
    NexT.utils.getScript(CONFIG.waline.libUrl, { condition: window.Waline })
  ).then(() => 
    Waline.init(Object.assign({}, CONFIG.waline,{ el: document.querySelector(CONFIG.waline.el) }))
  );
});</script><script src="https://cdn.jsdelivr.net/npm/darkmode-js@1.5.7/lib/darkmode-js.min.js"></script><script>var options = {
  bottom: '64px',
  right: '32px',
  left: 'unset',
  time: '0.5s',
  mixColor: 'transparent',
  backgroundColor: 'transparent',
  buttonColorDark: '#100f2c',
  buttonColorLight: '#fff',
  saveInCookies: true,
  label: '🌓',
  autoMatchOsTheme: true
}
const darkmode = new Darkmode(options);
window.darkmode = darkmode;
darkmode.showWidget();</script><script defer src="/_vercel/insights/script.js"></script><script defer src="/_vercel/speed-insights//script.js"></script><div class="moon-menu"><div class="moon-menu-items"><div id="moon-menu-item-back2bottom" class="moon-menu-item"><i class="fas fa-chevron-down"></i></div><div id="moon-menu-item-back2top" class="moon-menu-item"><i class="fas fa-chevron-up"></i></div></div><div class="moon-menu-button"><svg class="moon-menu-bg"><circle class="moon-menu-cricle" cx="50%" cy="50%" r="44%"></circle><circle class="moon-menu-border" cx="50%" cy="50%" r="48%"></circle></svg><div class="moon-menu-content"><div class="moon-menu-icon"><i class="fas fa-ellipsis-v"></i></div><div class="moon-menu-text"></div></div></div></div><script src="/js/injector.js"></script></body></html>